<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 4 Test de Fisher-Snedecor | Modèle linéaire général et modèle linéaire généralisé</title>
  <meta name="description" content="Chapitre 4 Test de Fisher-Snedecor | Modèle linéaire général et modèle linéaire généralisé" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 4 Test de Fisher-Snedecor | Modèle linéaire général et modèle linéaire généralisé" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 4 Test de Fisher-Snedecor | Modèle linéaire général et modèle linéaire généralisé" />
  
  
  

<meta name="author" content="Cathy Maugis-Rabusseau (INSA Toulouse / IMT)" />


<meta name="date" content="2021-10-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="EstML.html"/>
<link rel="next" href="singulier.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">UF Elements de modélisation statistique</a></li>
<li>      <img src="image/LogoInsaToulouse.jpg" height="20px" align="right"/>      </li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Préface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#modélisation-dune-réponse-quantitative"><i class="fa fa-check"></i><b>1.1</b> Modélisation d’une réponse quantitative</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#jeu-de-données-illustratif"><i class="fa fa-check"></i><b>1.1.1</b> Jeu de données illustratif</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#régression-linéaire"><i class="fa fa-check"></i><b>1.1.2</b> Régression linéaire</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#analyse-de-la-variance-anova"><i class="fa fa-check"></i><b>1.1.3</b> Analyse de la variance (ANOVA)</a></li>
<li class="chapter" data-level="1.1.4" data-path="intro.html"><a href="intro.html#analyse-de-covariance-ancova"><i class="fa fa-check"></i><b>1.1.4</b> Analyse de covariance (ANCOVA)</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#modélisation-dune-variable-binaire-de-comptage"><i class="fa fa-check"></i><b>1.2</b> Modélisation d’une variable binaire, de comptage, …</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#objectifs-du-cours"><i class="fa fa-check"></i><b>1.3</b> Objectifs du cours</a></li>
</ul></li>
<li class="part"><span><b>I Le modèle linéaire général</b></span></li>
<li class="chapter" data-level="2" data-path="DefML.html"><a href="DefML.html"><i class="fa fa-check"></i><b>2</b> Définitions générales</a><ul>
<li class="chapter" data-level="2.1" data-path="DefML.html"><a href="DefML.html#modlinreg"><i class="fa fa-check"></i><b>2.1</b> Modèle linéaire régulier</a></li>
<li class="chapter" data-level="2.2" data-path="DefML.html"><a href="DefML.html#exemples-de-modèle-linéaire-gaussien"><i class="fa fa-check"></i><b>2.2</b> Exemples de modèle linéaire gaussien</a><ul>
<li class="chapter" data-level="2.2.1" data-path="DefML.html"><a href="DefML.html#le-modèle-de-régression-linéaire"><i class="fa fa-check"></i><b>2.2.1</b> Le modèle de régression linéaire</a></li>
<li class="chapter" data-level="2.2.2" data-path="DefML.html"><a href="DefML.html#le-modèle-danalyse-de-la-variance"><i class="fa fa-check"></i><b>2.2.2</b> Le modèle d’analyse de la variance</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="DefML.html"><a href="DefML.html#en-résumé"><i class="fa fa-check"></i><b>2.3</b> En résumé</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="EstML.html"><a href="EstML.html"><i class="fa fa-check"></i><b>3</b> Estimation des paramètres</a><ul>
<li class="chapter" data-level="3.1" data-path="EstML.html"><a href="EstML.html#estimation-de-theta"><i class="fa fa-check"></i><b>3.1</b> Estimation de <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="3.2" data-path="EstML.html"><a href="EstML.html#valeurs-ajustées-et-résidus"><i class="fa fa-check"></i><b>3.2</b> Valeurs ajustées et résidus</a></li>
<li class="chapter" data-level="3.3" data-path="EstML.html"><a href="EstML.html#estimation-de-sigma2"><i class="fa fa-check"></i><b>3.3</b> Estimation de <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="3.4" data-path="EstML.html"><a href="EstML.html#erreurs-standards"><i class="fa fa-check"></i><b>3.4</b> Erreurs standards</a></li>
<li class="chapter" data-level="3.5" data-path="EstML.html"><a href="EstML.html#intervalle-de-confiance-de-theta_j-de-xtheta_i-et-de-x_0theta"><i class="fa fa-check"></i><b>3.5</b> Intervalle de confiance de <span class="math inline">\(\theta_j\)</span>, de <span class="math inline">\((X\theta)_i\)</span> et de <span class="math inline">\(X_0\theta\)</span></a><ul>
<li class="chapter" data-level="3.5.1" data-path="EstML.html"><a href="EstML.html#ICthetaj"><i class="fa fa-check"></i><b>3.5.1</b> Intervalle de confiance de <span class="math inline">\(\theta_j\)</span></a></li>
<li class="chapter" data-level="3.5.2" data-path="EstML.html"><a href="EstML.html#ICXthetai"><i class="fa fa-check"></i><b>3.5.2</b> Intervalle de confiance de <span class="math inline">\((X\theta)_i\)</span></a></li>
<li class="chapter" data-level="3.5.3" data-path="EstML.html"><a href="EstML.html#ICX0theta"><i class="fa fa-check"></i><b>3.5.3</b> Intervalle de confiance de <span class="math inline">\(X_0\theta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="EstML.html"><a href="EstML.html#ICpredit"><i class="fa fa-check"></i><b>3.6</b> Intervalles de prédiction</a></li>
<li class="chapter" data-level="3.7" data-path="EstML.html"><a href="EstML.html#qualité-dajustement"><i class="fa fa-check"></i><b>3.7</b> Qualité d’ajustement</a></li>
<li class="chapter" data-level="3.8" data-path="EstML.html"><a href="EstML.html#en-résumé-1"><i class="fa fa-check"></i><b>3.8</b> En résumé</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Test.html"><a href="Test.html"><i class="fa fa-check"></i><b>4</b> Test de Fisher-Snedecor</a><ul>
<li class="chapter" data-level="4.1" data-path="Test.html"><a href="Test.html#hypothèses-testées"><i class="fa fa-check"></i><b>4.1</b> Hypothèses testées</a><ul>
<li class="chapter" data-level="4.1.1" data-path="Test.html"><a href="Test.html#première-écriture"><i class="fa fa-check"></i><b>4.1.1</b> Première écriture</a></li>
<li class="chapter" data-level="4.1.2" data-path="Test.html"><a href="Test.html#seconde-écriture"><i class="fa fa-check"></i><b>4.1.2</b> Seconde écriture</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="Test.html"><a href="Test.html#le-test-de-fisher-snedecor"><i class="fa fa-check"></i><b>4.2</b> Le test de Fisher-Snedecor</a><ul>
<li class="chapter" data-level="4.2.1" data-path="Test.html"><a href="Test.html#principe"><i class="fa fa-check"></i><b>4.2.1</b> Principe</a></li>
<li class="chapter" data-level="4.2.2" data-path="Test.html"><a href="Test.html#comblinconjointes"><i class="fa fa-check"></i><b>4.2.2</b> La statistique de test</a></li>
<li class="chapter" data-level="4.2.3" data-path="Test.html"><a href="Test.html#règle-de-décision"><i class="fa fa-check"></i><b>4.2.3</b> Règle de décision</a></li>
<li class="chapter" data-level="4.2.4" data-path="Test.html"><a href="Test.html#comblin"><i class="fa fa-check"></i><b>4.2.4</b> Cas particulier où <span class="math inline">\(q=1\)</span> : Test de Student</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="Test.html"><a href="Test.html#intervalle-région-de-confiance-pour-ctheta"><i class="fa fa-check"></i><b>4.3</b> Intervalle (région) de confiance pour <span class="math inline">\(C\theta\)</span></a><ul>
<li class="chapter" data-level="4.3.1" data-path="Test.html"><a href="Test.html#ic-pour-ctheta-in-mathbbr"><i class="fa fa-check"></i><b>4.3.1</b> IC pour <span class="math inline">\(C\theta \in \mathbb{R}\)</span></a></li>
<li class="chapter" data-level="4.3.2" data-path="Test.html"><a href="Test.html#région-de-confiance-pour-ctheta-in-mathbbrq"><i class="fa fa-check"></i><b>4.3.2</b> Région de confiance pour <span class="math inline">\(C\theta \in \mathbb{R}^q\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="Test.html"><a href="Test.html#en-résumé-2"><i class="fa fa-check"></i><b>4.4</b> En résumé</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="singulier.html"><a href="singulier.html"><i class="fa fa-check"></i><b>5</b> Modèles singuliers, orthogonalité et importance des hypothèses sur les erreurs</a><ul>
<li class="chapter" data-level="5.1" data-path="singulier.html"><a href="singulier.html#quand-h1-h4-ne-sont-pas-respectées"><i class="fa fa-check"></i><b>5.1</b> Quand H1-H4 ne sont pas respectées…</a><ul>
<li class="chapter" data-level="5.1.1" data-path="singulier.html"><a href="singulier.html#propriétés-de-lestimateur-des-moindres-carrés-widehattheta"><i class="fa fa-check"></i><b>5.1.1</b> Propriétés de l’estimateur des moindres carrés <span class="math inline">\(\widehat{\theta}\)</span></a></li>
<li class="chapter" data-level="5.1.2" data-path="singulier.html"><a href="singulier.html#propriétés-de-lestimateur-des-moindres-carrés-widehatsigma2"><i class="fa fa-check"></i><b>5.1.2</b> Propriétés de l’estimateur des moindres carrés <span class="math inline">\(\widehat{\sigma}^2\)</span></a></li>
<li class="chapter" data-level="5.1.3" data-path="singulier.html"><a href="singulier.html#modèles-avec-corrélations"><i class="fa fa-check"></i><b>5.1.3</b> Modèles avec corrélations</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="singulier.html"><a href="singulier.html#ModSingulier"><i class="fa fa-check"></i><b>5.2</b> Modèles singuliers</a><ul>
<li class="chapter" data-level="5.2.1" data-path="singulier.html"><a href="singulier.html#contraintes-didentifiabilité"><i class="fa fa-check"></i><b>5.2.1</b> Contraintes d’identifiabilité</a></li>
<li class="chapter" data-level="5.2.2" data-path="singulier.html"><a href="singulier.html#fonctions-estimables-et-contrastes"><i class="fa fa-check"></i><b>5.2.2</b> Fonctions estimables et contrastes</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="singulier.html"><a href="singulier.html#orthogonalité"><i class="fa fa-check"></i><b>5.3</b> Orthogonalité</a><ul>
<li class="chapter" data-level="5.3.1" data-path="singulier.html"><a href="singulier.html#orthogonalité-pour-les-modèles-réguliers"><i class="fa fa-check"></i><b>5.3.1</b> Orthogonalité pour les modèles réguliers</a></li>
<li class="chapter" data-level="5.3.2" data-path="singulier.html"><a href="singulier.html#orthogonalité-pour-les-modèles-non-réguliers"><i class="fa fa-check"></i><b>5.3.2</b> Orthogonalité pour les modèles non-réguliers</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="singulier.html"><a href="singulier.html#en-résumé-3"><i class="fa fa-check"></i><b>5.4</b> En résumé</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>6</b> La régression linéaire</a><ul>
<li class="chapter" data-level="6.1" data-path="regression.html"><a href="regression.html#introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a><ul>
<li class="chapter" data-level="6.1.1" data-path="regression.html"><a href="regression.html#exemple-illustratif"><i class="fa fa-check"></i><b>6.1.1</b> Exemple illustratif</a></li>
<li class="chapter" data-level="6.1.2" data-path="regression.html"><a href="regression.html#problématique"><i class="fa fa-check"></i><b>6.1.2</b> Problématique</a></li>
<li class="chapter" data-level="6.1.3" data-path="regression.html"><a href="regression.html#le-modèle-de-régression-linéaire-simple"><i class="fa fa-check"></i><b>6.1.3</b> Le modèle de régression linéaire simple</a></li>
<li class="chapter" data-level="6.1.4" data-path="regression.html"><a href="regression.html#le-modèle-de-régression-linéaire-multiple"><i class="fa fa-check"></i><b>6.1.4</b> Le modèle de régression linéaire multiple</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="regression.html"><a href="regression.html#estimation"><i class="fa fa-check"></i><b>6.2</b> Estimation</a><ul>
<li class="chapter" data-level="6.2.1" data-path="regression.html"><a href="regression.html#résultats-généraux"><i class="fa fa-check"></i><b>6.2.1</b> Résultats généraux</a></li>
<li class="chapter" data-level="6.2.2" data-path="regression.html"><a href="regression.html#propriétés-en-régression-linéaire-simple"><i class="fa fa-check"></i><b>6.2.2</b> Propriétés en régression linéaire simple</a></li>
<li class="chapter" data-level="6.2.3" data-path="regression.html"><a href="regression.html#le-coefficient-r2"><i class="fa fa-check"></i><b>6.2.3</b> Le coefficient <span class="math inline">\(R^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="regression.html"><a href="regression.html#tests-et-intervalles-de-confiance"><i class="fa fa-check"></i><b>6.3</b> Tests et intervalles de confiance</a><ul>
<li class="chapter" data-level="6.3.1" data-path="regression.html"><a href="regression.html#test-de-nullité-dun-paramètre-du-modèle"><i class="fa fa-check"></i><b>6.3.1</b> Test de nullité d’un paramètre du modèle</a></li>
<li class="chapter" data-level="6.3.2" data-path="regression.html"><a href="regression.html#test-de-nullité-de-quelques-paramètres-du-modèle"><i class="fa fa-check"></i><b>6.3.2</b> Test de nullité de quelques paramètres du modèle</a></li>
<li class="chapter" data-level="6.3.3" data-path="regression.html"><a href="regression.html#test-de-nullité-de-tous-les-paramètres-du-modèle"><i class="fa fa-check"></i><b>6.3.3</b> Test de nullité de tous les paramètres du modèle</a></li>
<li class="chapter" data-level="6.3.4" data-path="regression.html"><a href="regression.html#intervalle-de-confiance-de-theta_j-de-xtheta_i-et-de-x_0theta-1"><i class="fa fa-check"></i><b>6.3.4</b> Intervalle de confiance de <span class="math inline">\(\theta_j\)</span>, de <span class="math inline">\((X\theta)_i\)</span> et de <span class="math inline">\(X_0\theta\)</span></a></li>
<li class="chapter" data-level="6.3.5" data-path="regression.html"><a href="regression.html#intervalle-de-prédiction"><i class="fa fa-check"></i><b>6.3.5</b> Intervalle de prédiction</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="regression.html"><a href="regression.html#sélection-des-variables-explicatives"><i class="fa fa-check"></i><b>6.4</b> Sélection des variables explicatives</a><ul>
<li class="chapter" data-level="6.4.1" data-path="regression.html"><a href="regression.html#cadre-général-de-sélection-de-modèles"><i class="fa fa-check"></i><b>6.4.1</b> Cadre général de sélection de modèles</a></li>
<li class="chapter" data-level="6.4.2" data-path="regression.html"><a href="regression.html#quelques-critères-pour-sélectionner-un-modèle"><i class="fa fa-check"></i><b>6.4.2</b> Quelques critères pour sélectionner un modèle</a></li>
<li class="chapter" data-level="6.4.3" data-path="regression.html"><a href="regression.html#algorithmes-de-sélection-de-variables"><i class="fa fa-check"></i><b>6.4.3</b> Algorithmes de sélection de variables</a></li>
<li class="chapter" data-level="6.4.4" data-path="regression.html"><a href="regression.html#illustration-sur-lexemple"><i class="fa fa-check"></i><b>6.4.4</b> Illustration sur l’exemple</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="regression.html"><a href="regression.html#régression-linéaire-régularisée"><i class="fa fa-check"></i><b>6.5</b> Régression linéaire régularisée</a><ul>
<li class="chapter" data-level="6.5.1" data-path="regression.html"><a href="regression.html#régression-ridge"><i class="fa fa-check"></i><b>6.5.1</b> Régression ridge</a></li>
<li class="chapter" data-level="6.5.2" data-path="regression.html"><a href="regression.html#régression-lasso"><i class="fa fa-check"></i><b>6.5.2</b> Régression Lasso</a></li>
<li class="chapter" data-level="6.5.3" data-path="regression.html"><a href="regression.html#régression-elastic-net"><i class="fa fa-check"></i><b>6.5.3</b> Régression Elastic-Net</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="regression.html"><a href="regression.html#ValidationMod"><i class="fa fa-check"></i><b>6.6</b> Validation du modèle</a><ul>
<li class="chapter" data-level="6.6.1" data-path="regression.html"><a href="regression.html#contrôle-graphique-a-posteriori"><i class="fa fa-check"></i><b>6.6.1</b> Contrôle graphique a posteriori</a></li>
<li class="chapter" data-level="6.6.2" data-path="regression.html"><a href="regression.html#pour-vérifier-les-hypothèses-h1-et-h2-adéquation-et-homoscédasticité"><i class="fa fa-check"></i><b>6.6.2</b> Pour vérifier les hypothèses H1 et H2 : adéquation et homoscédasticité</a></li>
<li class="chapter" data-level="6.6.3" data-path="regression.html"><a href="regression.html#pour-vérifier-lhypothèse-h3-indépendance"><i class="fa fa-check"></i><b>6.6.3</b> Pour vérifier l’hypothèse H3 : indépendance</a></li>
<li class="chapter" data-level="6.6.4" data-path="regression.html"><a href="regression.html#pour-vérifier-lhypothèse-h4-gaussianité"><i class="fa fa-check"></i><b>6.6.4</b> Pour vérifier l’hypothèse H4 : gaussianité</a></li>
<li class="chapter" data-level="6.6.5" data-path="regression.html"><a href="regression.html#détection-de-données-aberrantes"><i class="fa fa-check"></i><b>6.6.5</b> Détection de données aberrantes</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="regression.html"><a href="regression.html#en-résumé-4"><i class="fa fa-check"></i><b>6.7</b> En résumé</a></li>
<li class="chapter" data-level="6.8" data-path="regression.html"><a href="regression.html#quelques-codes-python"><i class="fa fa-check"></i><b>6.8</b> Quelques codes python</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ANOVA.html"><a href="ANOVA.html"><i class="fa fa-check"></i><b>7</b> Analyse de variance (ANOVA)</a><ul>
<li class="chapter" data-level="7.1" data-path="ANOVA.html"><a href="ANOVA.html#vocabulaire"><i class="fa fa-check"></i><b>7.1</b> Vocabulaire</a></li>
<li class="chapter" data-level="7.2" data-path="ANOVA.html"><a href="ANOVA.html#analyse-de-variance-à-un-facteur"><i class="fa fa-check"></i><b>7.2</b> Analyse de variance à un facteur</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ANOVA.html"><a href="ANOVA.html#exemple-et-notations"><i class="fa fa-check"></i><b>7.2.1</b> Exemple et notations</a></li>
<li class="chapter" data-level="7.2.2" data-path="ANOVA.html"><a href="ANOVA.html#modèle-régulier"><i class="fa fa-check"></i><b>7.2.2</b> Modèle régulier</a></li>
<li class="chapter" data-level="7.2.3" data-path="ANOVA.html"><a href="ANOVA.html#modèle-singulier"><i class="fa fa-check"></i><b>7.2.3</b> Modèle singulier</a></li>
<li class="chapter" data-level="7.2.4" data-path="ANOVA.html"><a href="ANOVA.html#prédictions-résidus-et-variance"><i class="fa fa-check"></i><b>7.2.4</b> Prédictions, résidus et variance</a></li>
<li class="chapter" data-level="7.2.5" data-path="ANOVA.html"><a href="ANOVA.html#intervalle-de-confiance-et-test-sur-leffet-facteur"><i class="fa fa-check"></i><b>7.2.5</b> Intervalle de confiance et test sur l’effet facteur</a></li>
<li class="chapter" data-level="7.2.6" data-path="ANOVA.html"><a href="ANOVA.html#test-deffet-du-facteur"><i class="fa fa-check"></i><b>7.2.6</b> Test d’effet du facteur</a></li>
<li class="chapter" data-level="7.2.7" data-path="ANOVA.html"><a href="ANOVA.html#tableau-danalyse-de-la-variance-à-un-facteur"><i class="fa fa-check"></i><b>7.2.7</b> Tableau d’analyse de la variance à un facteur</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ANOVA.html"><a href="ANOVA.html#analyse-de-variance-à-deux-facteurs"><i class="fa fa-check"></i><b>7.3</b> Analyse de variance à deux facteurs</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ANOVA.html"><a href="ANOVA.html#notations-et-exemple"><i class="fa fa-check"></i><b>7.3.1</b> Notations et exemple</a></li>
<li class="chapter" data-level="7.3.2" data-path="ANOVA.html"><a href="ANOVA.html#modélisation"><i class="fa fa-check"></i><b>7.3.2</b> Modélisation</a></li>
<li class="chapter" data-level="7.3.3" data-path="ANOVA.html"><a href="ANOVA.html#estimation-des-paramètres"><i class="fa fa-check"></i><b>7.3.3</b> Estimation des paramètres</a></li>
<li class="chapter" data-level="7.3.4" data-path="ANOVA.html"><a href="ANOVA.html#prédiction-résidus-et-variance"><i class="fa fa-check"></i><b>7.3.4</b> Prédiction, résidus et variance</a></li>
<li class="chapter" data-level="7.3.5" data-path="ANOVA.html"><a href="ANOVA.html#décomposition-de-la-variabilité"><i class="fa fa-check"></i><b>7.3.5</b> Décomposition de la variabilité</a></li>
<li class="chapter" data-level="7.3.6" data-path="ANOVA.html"><a href="ANOVA.html#le-diagramme-dinteractions"><i class="fa fa-check"></i><b>7.3.6</b> Le diagramme d’interactions</a></li>
<li class="chapter" data-level="7.3.7" data-path="ANOVA.html"><a href="ANOVA.html#tests-dhypothèses"><i class="fa fa-check"></i><b>7.3.7</b> Tests d’hypothèses</a></li>
<li class="chapter" data-level="7.3.8" data-path="ANOVA.html"><a href="ANOVA.html#test-dabsence-deffet-du-facteur-b"><i class="fa fa-check"></i><b>7.3.8</b> Test d’absence d’effet du facteur <span class="math inline">\(B\)</span></a></li>
<li class="chapter" data-level="7.3.9" data-path="ANOVA.html"><a href="ANOVA.html#tableau-danalyse-de-variance-à-deux-facteurs-croisés-dans-le-cas-dun-plan-orthogonal"><i class="fa fa-check"></i><b>7.3.9</b> Tableau d’analyse de variance à deux facteurs croisés dans le cas d’un plan orthogonal</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ANOVA.html"><a href="ANOVA.html#en-résumé-5"><i class="fa fa-check"></i><b>7.4</b> En résumé</a></li>
<li class="chapter" data-level="7.5" data-path="ANOVA.html"><a href="ANOVA.html#quelques-codes-en-python"><i class="fa fa-check"></i><b>7.5</b> Quelques codes en python</a><ul>
<li class="chapter" data-level="7.5.1" data-path="ANOVA.html"><a href="ANOVA.html#exemple-danova-à-un-facteur"><i class="fa fa-check"></i><b>7.5.1</b> Exemple d’ANOVA à un facteur</a></li>
<li class="chapter" data-level="7.5.2" data-path="ANOVA.html"><a href="ANOVA.html#exemple-danova-à-deux-facteurs"><i class="fa fa-check"></i><b>7.5.2</b> Exemple d’ANOVA à deux facteurs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ANCOVA.html"><a href="ANCOVA.html"><i class="fa fa-check"></i><b>8</b> Analyse de covariance (ANCOVA)</a><ul>
<li class="chapter" data-level="8.1" data-path="ANCOVA.html"><a href="ANCOVA.html#les-données"><i class="fa fa-check"></i><b>8.1</b> Les données</a></li>
<li class="chapter" data-level="8.2" data-path="ANCOVA.html"><a href="ANCOVA.html#modélisation-1"><i class="fa fa-check"></i><b>8.2</b> Modélisation</a><ul>
<li class="chapter" data-level="8.2.1" data-path="ANCOVA.html"><a href="ANCOVA.html#modélisation-régulière"><i class="fa fa-check"></i><b>8.2.1</b> Modélisation régulière</a></li>
<li class="chapter" data-level="8.2.2" data-path="ANCOVA.html"><a href="ANCOVA.html#modélisation-singulière"><i class="fa fa-check"></i><b>8.2.2</b> Modélisation singulière</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ANCOVA.html"><a href="ANCOVA.html#estimation-des-paramètres-1"><i class="fa fa-check"></i><b>8.3</b> Estimation des paramètres</a></li>
<li class="chapter" data-level="8.4" data-path="ANCOVA.html"><a href="ANCOVA.html#tests-dhypothèses-1"><i class="fa fa-check"></i><b>8.4</b> Tests d’hypothèses</a><ul>
<li class="chapter" data-level="8.4.1" data-path="ANCOVA.html"><a href="ANCOVA.html#absence-de-tout-effet"><i class="fa fa-check"></i><b>8.4.1</b> Absence de tout effet</a></li>
<li class="chapter" data-level="8.4.2" data-path="ANCOVA.html"><a href="ANCOVA.html#test-dabsence-dinteraction"><i class="fa fa-check"></i><b>8.4.2</b> Test d’absence d’interaction</a></li>
<li class="chapter" data-level="8.4.3" data-path="ANCOVA.html"><a href="ANCOVA.html#test-dabsence-de-leffet-de-la-covariable-z"><i class="fa fa-check"></i><b>8.4.3</b> Test d’absence de l’effet de la covariable z</a></li>
<li class="chapter" data-level="8.4.4" data-path="ANCOVA.html"><a href="ANCOVA.html#test-dabsence-de-leffet-facteur-t"><i class="fa fa-check"></i><b>8.4.4</b> Test d’absence de l’effet facteur T</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ANCOVA.html"><a href="ANCOVA.html#en-résumé-6"><i class="fa fa-check"></i><b>8.5</b> En résumé</a></li>
<li class="chapter" data-level="8.6" data-path="ANCOVA.html"><a href="ANCOVA.html#quelques-codes-en-python-1"><i class="fa fa-check"></i><b>8.6</b> Quelques codes en python</a></li>
</ul></li>
<li class="part"><span><b>II Le modèle linéaire généralisé</b></span></li>
<li class="chapter" data-level="9" data-path="GLM.html"><a href="GLM.html"><i class="fa fa-check"></i><b>9</b> Principe du modèle linéaire généralisé</a><ul>
<li class="chapter" data-level="9.1" data-path="GLM.html"><a href="GLM.html#introduction-1"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="GLM.html"><a href="GLM.html#caractérisation-dun-modèle-linéaire-généralisé"><i class="fa fa-check"></i><b>9.2</b> Caractérisation d’un modèle linéaire généralisé</a><ul>
<li class="chapter" data-level="9.2.1" data-path="GLM.html"><a href="GLM.html#loi-de-la-variable-réponse-y"><i class="fa fa-check"></i><b>9.2.1</b> Loi de la variable réponse <span class="math inline">\(Y\)</span></a></li>
<li class="chapter" data-level="9.2.2" data-path="GLM.html"><a href="GLM.html#prédicteur-linéaire"><i class="fa fa-check"></i><b>9.2.2</b> Prédicteur linéaire</a></li>
<li class="chapter" data-level="9.2.3" data-path="GLM.html"><a href="GLM.html#fonction-de-lien"><i class="fa fa-check"></i><b>9.2.3</b> Fonction de lien</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="GLM.html"><a href="GLM.html#EstimMLG"><i class="fa fa-check"></i><b>9.3</b> Estimation</a><ul>
<li class="chapter" data-level="9.3.1" data-path="GLM.html"><a href="GLM.html#estimation-par-maximum-de-vraisemblance"><i class="fa fa-check"></i><b>9.3.1</b> Estimation par maximum de vraisemblance</a></li>
<li class="chapter" data-level="9.3.2" data-path="GLM.html"><a href="GLM.html#algorithmes-de-newton-raphson-et-fisher-scoring"><i class="fa fa-check"></i><b>9.3.2</b> Algorithmes de Newton-Raphson et Fisher-scoring</a></li>
<li class="chapter" data-level="9.3.3" data-path="GLM.html"><a href="GLM.html#equations-de-vraisemblance"><i class="fa fa-check"></i><b>9.3.3</b> Equations de vraisemblance</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="GLM.html"><a href="GLM.html#NormalitéAsymptotique"><i class="fa fa-check"></i><b>9.4</b> Loi asymptotique de l’EMV et inférence</a></li>
<li class="chapter" data-level="9.5" data-path="GLM.html"><a href="GLM.html#tests-dhypothèses-2"><i class="fa fa-check"></i><b>9.5</b> Tests d’hypothèses</a><ul>
<li class="chapter" data-level="9.5.1" data-path="GLM.html"><a href="GLM.html#test-de-modèles-emboîtés"><i class="fa fa-check"></i><b>9.5.1</b> Test de modèles emboîtés</a></li>
<li class="chapter" data-level="9.5.2" data-path="GLM.html"><a href="GLM.html#TestParamMLG"><i class="fa fa-check"></i><b>9.5.2</b> Test d’un paramètre <span class="math inline">\(\theta_j\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="GLM.html"><a href="GLM.html#MLGIC"><i class="fa fa-check"></i><b>9.6</b> Intervalle de confiance pour <span class="math inline">\(\theta_j\)</span></a><ul>
<li class="chapter" data-level="9.6.1" data-path="GLM.html"><a href="GLM.html#par-wald"><i class="fa fa-check"></i><b>9.6.1</b> Par Wald</a></li>
<li class="chapter" data-level="9.6.2" data-path="GLM.html"><a href="GLM.html#fondé-sur-le-rapport-de-vraisemblances"><i class="fa fa-check"></i><b>9.6.2</b> Fondé sur le rapport de vraisemblances</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="GLM.html"><a href="GLM.html#qualité-dajustement-1"><i class="fa fa-check"></i><b>9.7</b> Qualité d’ajustement</a><ul>
<li class="chapter" data-level="9.7.1" data-path="GLM.html"><a href="GLM.html#le-pseudo-r2"><i class="fa fa-check"></i><b>9.7.1</b> Le pseudo <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="9.7.2" data-path="GLM.html"><a href="GLM.html#le-chi2-de-pearson-généralisé"><i class="fa fa-check"></i><b>9.7.2</b> Le <span class="math inline">\(\chi^2\)</span> de Pearson généralisé</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="GLM.html"><a href="GLM.html#ResidusGLM"><i class="fa fa-check"></i><b>9.8</b> Diagnostic, résidus</a></li>
<li class="chapter" data-level="9.9" data-path="GLM.html"><a href="GLM.html#en-résumé-7"><i class="fa fa-check"></i><b>9.9</b> En résumé</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="RegLogistique.html"><a href="RegLogistique.html"><i class="fa fa-check"></i><b>10</b> Régression logistique</a><ul>
<li class="chapter" data-level="10.1" data-path="RegLogistique.html"><a href="RegLogistique.html#introduction-2"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="RegLogistique.html"><a href="RegLogistique.html#pourquoi-des-modèles-particuliers"><i class="fa fa-check"></i><b>10.2</b> Pourquoi des modèles particuliers ?</a></li>
<li class="chapter" data-level="10.3" data-path="RegLogistique.html"><a href="RegLogistique.html#odds-et-odds-ratio"><i class="fa fa-check"></i><b>10.3</b> Odds et odds ratio</a></li>
<li class="chapter" data-level="10.4" data-path="RegLogistique.html"><a href="RegLogistique.html#régression-logistique-simple"><i class="fa fa-check"></i><b>10.4</b> Régression logistique simple</a><ul>
<li class="chapter" data-level="10.4.1" data-path="RegLogistique.html"><a href="RegLogistique.html#subquanti"><i class="fa fa-check"></i><b>10.4.1</b> Avec une variable explicative quantitative</a></li>
<li class="chapter" data-level="10.4.2" data-path="RegLogistique.html"><a href="RegLogistique.html#sect1expquali"><i class="fa fa-check"></i><b>10.4.2</b> Avec une variable explicative qualitative</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="RegLogistique.html"><a href="RegLogistique.html#régression-logistique-multiple"><i class="fa fa-check"></i><b>10.5</b> Régression logistique multiple</a><ul>
<li class="chapter" data-level="10.5.1" data-path="RegLogistique.html"><a href="RegLogistique.html#modèle-sans-interaction"><i class="fa fa-check"></i><b>10.5.1</b> Modèle sans interaction</a></li>
<li class="chapter" data-level="10.5.2" data-path="RegLogistique.html"><a href="RegLogistique.html#modèle-avec-interactions"><i class="fa fa-check"></i><b>10.5.2</b> Modèle avec interactions</a></li>
<li class="chapter" data-level="10.5.3" data-path="RegLogistique.html"><a href="RegLogistique.html#etude-complémentaire-du-modèle-retenu"><i class="fa fa-check"></i><b>10.5.3</b> Etude complémentaire du modèle retenu</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="RegLogistique.html"><a href="RegLogistique.html#quelques-codes-avec-python"><i class="fa fa-check"></i><b>10.6</b> Quelques codes avec python</a></li>
<li class="chapter" data-level="10.7" data-path="RegLogistique.html"><a href="RegLogistique.html#régression-polytomique"><i class="fa fa-check"></i><b>10.7</b> Régression polytomique</a><ul>
<li class="chapter" data-level="10.7.1" data-path="RegLogistique.html"><a href="RegLogistique.html#régression-multinomiale-ou-polytomique-non-ordonnée"><i class="fa fa-check"></i><b>10.7.1</b> Régression multinomiale ou polytomique non-ordonnée</a></li>
<li class="chapter" data-level="10.7.2" data-path="RegLogistique.html"><a href="RegLogistique.html#régression-polytomique-ordonnée"><i class="fa fa-check"></i><b>10.7.2</b> Régression polytomique ordonnée</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="RegLogLin.html"><a href="RegLogLin.html"><i class="fa fa-check"></i><b>11</b> Régression de Poisson / régression loglinéaire</a><ul>
<li class="chapter" data-level="11.1" data-path="RegLogLin.html"><a href="RegLogLin.html#modèle-de-régression-loglinéaire"><i class="fa fa-check"></i><b>11.1</b> Modèle de régression loglinéaire</a><ul>
<li class="chapter" data-level="11.1.1" data-path="RegLogLin.html"><a href="RegLogLin.html#pourquoi-un-modèle-particulier"><i class="fa fa-check"></i><b>11.1.1</b> Pourquoi un modèle particulier ?</a></li>
<li class="chapter" data-level="11.1.2" data-path="RegLogLin.html"><a href="RegLogLin.html#estimation-des-paramètres-3"><i class="fa fa-check"></i><b>11.1.2</b> Estimation des paramètres</a></li>
<li class="chapter" data-level="11.1.3" data-path="RegLogLin.html"><a href="RegLogLin.html#ajustement-et-prédiction"><i class="fa fa-check"></i><b>11.1.3</b> Ajustement et prédiction</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="RegLogLin.html"><a href="RegLogLin.html#exemple-de-régression-loglinéaire-avec-r"><i class="fa fa-check"></i><b>11.2</b> Exemple de régression loglinéaire avec R</a><ul>
<li class="chapter" data-level="11.2.1" data-path="RegLogLin.html"><a href="RegLogLin.html#régression-loglinéaire-simple"><i class="fa fa-check"></i><b>11.2.1</b> Régression loglinéaire simple</a></li>
<li class="chapter" data-level="11.2.2" data-path="RegLogLin.html"><a href="RegLogLin.html#régression-loglinéaire-multiple"><i class="fa fa-check"></i><b>11.2.2</b> Régression loglinéaire multiple</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="RegLogLin.html"><a href="RegLogLin.html#sur-dispersion-et-modèle-binomial-négatif"><i class="fa fa-check"></i><b>11.3</b> Sur-dispersion et modèle binomial négatif</a></li>
<li class="chapter" data-level="11.4" data-path="RegLogLin.html"><a href="RegLogLin.html#quelques-codes-avec-python-1"><i class="fa fa-check"></i><b>11.4</b> Quelques codes avec python</a></li>
</ul></li>
<li class="appendix"><span><b>Annexes</b></span></li>
<li class="chapter" data-level="A" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html"><i class="fa fa-check"></i><b>A</b> Rappels de probabilités, statistiques et d’optimisation</a><ul>
<li class="chapter" data-level="A.1" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#rappels-sur-les-échantillons-gaussiens"><i class="fa fa-check"></i><b>A.1</b> Rappels sur les échantillons gaussiens</a><ul>
<li class="chapter" data-level="A.1.1" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#la-loi-normale"><i class="fa fa-check"></i><b>A.1.1</b> La loi normale</a></li>
<li class="chapter" data-level="A.1.2" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#vecteurs-gaussiens"><i class="fa fa-check"></i><b>A.1.2</b> Vecteurs gaussiens</a></li>
<li class="chapter" data-level="A.1.3" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#loi-du-khi-deux-loi-de-student-loi-de-fisher"><i class="fa fa-check"></i><b>A.1.3</b> Loi du khi-deux, loi de Student, loi de Fisher</a></li>
<li class="chapter" data-level="A.1.4" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#estimation-de-la-moyenne-et-de-la-variance-dun-échantillon-gaussien"><i class="fa fa-check"></i><b>A.1.4</b> Estimation de la moyenne et de la variance d’un échantillon gaussien</a></li>
<li class="chapter" data-level="A.1.5" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#construction-dintervalles-de-confiance"><i class="fa fa-check"></i><b>A.1.5</b> Construction d’intervalles de confiance</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#estimation-sans-biais-de-variance-minimale"><i class="fa fa-check"></i><b>A.2</b> Estimation sans biais de variance minimale</a></li>
<li class="chapter" data-level="A.3" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#Newton-Raphson"><i class="fa fa-check"></i><b>A.3</b> La méthode de Newton-Raphson</a></li>
<li class="chapter" data-level="A.4" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#théorème-central-limite-condition-de-lindeberg"><i class="fa fa-check"></i><b>A.4</b> Théorème central limite: condition de Lindeberg</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html"><i class="fa fa-check"></i><b>B</b> Preuves de quelques résultats du cours</a><ul>
<li class="chapter" data-level="B.1" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html#ProofFisher"><i class="fa fa-check"></i><b>B.1</b> Preuve pour le test de Fisher</a></li>
<li class="chapter" data-level="B.2" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html#annexe:ortho"><i class="fa fa-check"></i><b>B.2</b> Preuve de la proposition @ref(prp:Proportho)</a></li>
<li class="chapter" data-level="B.3" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html#annexe:risque"><i class="fa fa-check"></i><b>B.3</b> Preuve de la proposition @ref(prp:risque)</a></li>
<li class="chapter" data-level="B.4" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html#annexe:KL"><i class="fa fa-check"></i><b>B.4</b> Preuve de la proposition @ref(prp:KL)</a></li>
<li class="chapter" data-level="B.5" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html#annexe:Mallows"><i class="fa fa-check"></i><b>B.5</b> Critère du <span class="math inline">\(C_p\)</span> de Mallows</a></li>
<li class="chapter" data-level="B.6" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html#annexe:Sj"><i class="fa fa-check"></i><b>B.6</b> Preuve de la proposition @ref(prp:eqSj)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li>Cathy Maugis-Rabusseau</li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modèle linéaire général et modèle linéaire généralisé</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="Test" class="section level1">
<h1><span class="header-section-number">Chapitre 4</span> Test de Fisher-Snedecor</h1>
<p>Nous allons nous intéresser dans ce chapitre à un certain nombre de tests pouvant être mis en oeuvre sur le modèle linéaire. Nous supposerons pendant toute cette partie que les hypothèses H1-H4 sont vérifiées. Les tests présentés ci-dessous ne peuvent être utilisés si ces hypothèses ne sont pas satisfaites.</p>
<div id="hypothèses-testées" class="section level2">
<h2><span class="header-section-number">4.1</span> Hypothèses testées</h2>
<p>On considère un modèle linéaire gaussien
<span class="math display" id="eq:defmod2">\[\begin{equation}
\tag{4.1}
Y=X\theta +\varepsilon \, \mbox{ avec } \varepsilon \sim \mathcal{N}_n\left(0_n,\sigma^2 I_n\right)
\end{equation}\]</span></p>
<p>et on s’intéresse à examiner la nullité de certaines composantes du paramètre <span class="math inline">\(\theta\)</span> ou de certaines combinaisons linéaires des composantes de <span class="math inline">\(\theta\)</span>, par exemple : <span class="math inline">\(\theta_j=0 \, ; \, \theta_j=\theta_k=0\)</span> ou <span class="math inline">\(\theta_j=\theta_k\)</span>. Ces hypothèses reposent sur la notion de modèles emboîtés : deux modèles sont dits <strong>emboîtés</strong> si l’un peut être considéré comme un cas particulier de l’autre. Cela revient à comparer un modèle de référence à un modèle réduit ou contraint. Cette approche vise donc à déterminer si le modèle utilisé peut être oui ou non simplifié. Voici deux exemples de sous-modèles :
<span class="math display">\[
\begin{array}{ll}
\mbox{Modèle général de la régression linéaire simple : } &amp; Y_i=a+bX_i+\varepsilon_i\\
\mbox{Sous-modèle avec nullité de la pente : } &amp; Y_i=a+\varepsilon_i\\
 &amp; \\
\mbox{Modèle général de l&#39;analyse de variance à 1 facteur :  }
&amp; Y_{ij}=\mu_i+\varepsilon_{ij}\\
\mbox{Sous-modèle avec égalité des groupes : } &amp; Y_{ij}=\mu+\varepsilon_{ij} 
\end{array}
\]</span></p>
<p>Par la suite, nous allons considérer deux écritures équivalentes de l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span>.<br />
<!--la première est plus pratique et la deuxième est plus théorique.--></p>
<div id="première-écriture" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Première écriture</h3>
<p>Pour spécifier la nullité de certaines composantes du paramètre <span class="math inline">\(\theta\)</span>, on introduit la matrice <span class="math inline">\(C \in \mathcal{M}_{qk}(\mathbb{R})\)</span> où <span class="math inline">\(k\)</span> désigne le nombre de paramètres du modèle de référence et <span class="math inline">\(q\)</span> le nombre de contraintes testées <span class="math inline">\((1 \leq q \leq k)\)</span> telle que
<span class="math display">\[\mathcal{H}_0 : C\theta = 0_{q}.\]</span>
La matrice <span class="math inline">\(C\)</span> sera supposée être de rang <span class="math inline">\(q\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-13" class="example"><strong>Example 4.1  </strong></span>On suppose un modèle à <span class="math inline">\(k=3\)</span> paramètres. Voici trois exemples :</p>
<ul>
<li>Tester l’hypothèse <span class="math inline">\(\mathcal{H}_0 : \theta_2=0\)</span> revient à poser <span class="math inline">\(\mathcal{H}_0 : C&#39;\theta=0\)</span> avec <span class="math inline">\(C&#39;=\left(\begin{array}{ccc} 0 &amp; 1 &amp; 0 \end{array} \right)\)</span> et <span class="math inline">\(q=1\)</span>.</li>
<li>Tester l’hypothèse <span class="math inline">\(\mathcal{H}_0 : \theta_3=\theta_2\)</span> revient à poser <span class="math inline">\(\mathcal{H}_0 : C&#39;\theta= 0\)</span> avec <span class="math inline">\(C&#39;= \left(\begin{array}{ccc} 0 &amp; -1 &amp; 1 \end{array} \right)\)</span> ou <span class="math inline">\(C&#39;=\left(\begin{array}{ccc} 0 &amp; 1 &amp; -1 \end{array} \right)\)</span> et <span class="math inline">\(q=1\)</span>.</li>
<li>Tester l’hypothèse <span class="math inline">\(\mathcal{H}_0 : \theta_3=\theta_2=0\)</span> revient à poser <span class="math inline">\(\mathcal{H}_0 : C&#39;\theta=0_{2}\)</span> avec <span class="math inline">\(\displaystyle C&#39;=\left(\begin{array}{ccc} 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{array} \right)\)</span> et <span class="math inline">\(q=2\)</span>.</li>
</ul>
</div>
</div>
<div id="seconde-écriture" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Seconde écriture</h3>
<p>Plaçons-nous dans le cadre général du modèle linéaire. Soit le modèle <a href="Test.html#eq:defmod2">(4.1)</a> et soit <span class="math inline">\(Z\)</span> une matrice telle que <span class="math inline">\(Im(Z) \subset Im(X)\)</span> et <span class="math inline">\(k_0=dim( Im(Z) ) &lt;k=dim( Im (X))\)</span>. Le modèle défini par
<span class="math display" id="eq:sousmodele">\[\begin{equation}
Y= Z \beta +\varepsilon,
\tag{4.2}
\end{equation}\]</span>
est appelé <strong>sous-modèle</strong> issu du modèle linéaire défini en <a href="Test.html#eq:defmod2">(4.1)</a>. Le plus souvent, <span class="math inline">\(Z\)</span> est la matrice constituée de <span class="math inline">\(k_0\)</span> vecteurs colonnes de <span class="math inline">\(X\)</span> avec <span class="math inline">\(k_0&lt;k\)</span> et <span class="math inline">\(\beta\)</span> est un vecteur de longueur <span class="math inline">\(k_0\)</span>. Nous notons alors <span class="math inline">\(SSR_0\)</span> la somme des carrés des résidus de ce sous-modèle, associée à <span class="math inline">\(n-k_0\)</span> degrés de liberté et définie de la façon suivante
<span class="math display">\[SSR_0=\|Y-Z\widehat{\beta}\|^2,\]</span>
où <span class="math inline">\(\widehat{\beta}\)</span> est l’estimateur des moindres carrés issus du modèle <a href="Test.html#eq:sousmodele">(4.2)</a> pour <span class="math inline">\(\beta\)</span>.
Dans la mesure où <span class="math inline">\(Im(Z) \subset Im(X)\)</span> et par définition des estimateurs des moindre carrés, nous pouvons remarquer que <span class="math inline">\(SSR_0 \geq SSR\)</span>.</p>
<p>Il peut être parfois intéressant d’essayer de savoir si les observations sont issues du modèle <a href="Test.html#eq:defmod2">(4.1)</a> ou <a href="Test.html#eq:sousmodele">(4.2)</a>. Soit le modèle défini par :
<span class="math display">\[Y= R+ \varepsilon.\]</span>
Tester la présence d’un sous-modèle revient donc à tester :
<span class="math display">\[
\mathcal{H}_0 : R \in Im (Z)
  \textrm{  contre  } \mathcal{H}_1 :  R \in Im(X) \backslash  Im(Z).
\]</span></p>
<!--
%\subsection{Calculs sous $\Hc_0$}
%L'hypothèse nulle étant définie, on a donc posé un modèle contraint ou sous-modèle que l'on va estimer en supposant $\Hc_0$ vraie.
%
%On a noté $\widehat{\theta}$ l'estimateur du paramètre $\theta$ correspondant au modèle de référence (\ref{defmod2}). On note $\widehat{\beta}$ l'estimateur du paramètre $\beta$ sous $\Hc_0$ pour le modèle contraint (\ref{sous-modèle}). On peut obtenir, sous $\Hc_0$, les valeurs prédites $\widehat{Y_0}$ et les résidus estimés $\widehat{\varepsilon_0}=Y-\widehat{Y_0}$. Le test de Fisher consiste alors à comparer les estimateurs du modèle de référence et celles sous $\Hc_0$.
\newpage
-->
</div>
</div>
<div id="le-test-de-fisher-snedecor" class="section level2">
<h2><span class="header-section-number">4.2</span> Le test de Fisher-Snedecor</h2>
<div id="principe" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Principe</h3>
<p>Le test de Fisher-Snedecor est la règle de décision qui permet de décider si on rejette ou ne rejette pas <span class="math inline">\(\displaystyle \mathcal{H}_0 : C\theta =0_{q}\)</span>, c’est-à-dire <span class="math inline">\(\mathcal{H}_0: R \in Im(Z)\)</span> :</p>
<ul>
<li>Rejeter <span class="math inline">\(\mathcal{H}_0\)</span>, c’est décider que <span class="math inline">\(C\theta \neq 0_{q}\)</span>, c’est-à-dire que certaines composantes de <span class="math inline">\(C\theta\)</span> ne sont pas nulles. Nous n’avons donc pas confiance dans le sous-modèle et nous préfèrerons continuer à travailler avec le modèle de référence.</li>
<li>Ne pas rejeter <span class="math inline">\(\mathcal{H}_0\)</span>, c’est ne pas exclure que toutes les composantes de <span class="math inline">\(C\theta\)</span> sont nulles. Dans ce cas, il n’est pas nécessaire de conserver un modèle trop compliqué et nous préfèrerons conserver le modèle contraint pour expliquer les données.</li>
</ul>
</div>
<div id="comblinconjointes" class="section level3">
<h3><span class="header-section-number">4.2.2</span> La statistique de test</h3>
<div class="theorem">
<p><span id="thm:TestF" class="theorem"><strong>Theorem 4.1  </strong></span>Dans le cadre du modèle linéaire général <a href="Test.html#eq:defmod2">(4.1)</a> avec les hypothèses H1-H4 et les notations précédentes, sous l’hypothèse nulle <span class="math inline">\(\mathcal{H}_0\)</span> (le sous-modèle <a href="Test.html#eq:sousmodele">(4.2)</a> est vrai), la variable
<span class="math display">\[F =\frac{(SSR_0- SSR)/(k-k_0)}{SSR/(n-k)}  = \frac{\|X\widehat{\theta} - Z\widehat{\beta}\|^2 / (k-k_0)}{\|Y - X\widehat \theta\|^2 / (n-k)} \underset{\mathcal{H}_0}{\sim} \mathcal{F}(k-k_0,n-k)\]</span>
(loi de Fisher de paramètres <span class="math inline">\((k-k_0,n-k)\)</span>).</p>
<p>De plus, <span class="math inline">\(F\)</span> est indépendante de <span class="math inline">\(Z\widehat{\beta}\)</span> (calculé sous l’hypothèse <span class="math inline">\(\mathcal{H}_0\)</span>).</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-14" class="exercise"><strong>Exercise 4.1  </strong></span>Le but de l’exercice est de démontrer le théorème <a href="Test.html#thm:TestF">4.1</a>.</p>
<ul>
<li>Montrez que <span class="math inline">\(SSR = \|P_{[X]^\perp}\varepsilon\|^2 \sim \sigma^2 \chi^2(n-k)\)</span></li>
<li>Soit <span class="math inline">\(A\)</span> un sous-espace vectoriel de <span class="math inline">\(Im(X)=[X]\)</span> tel que <span class="math inline">\(A \stackrel{\perp}{\oplus} Im(Z) = Im(X)\)</span>, <span class="math inline">\(dim(A)=k-k_0\)</span>. Montrez que <span class="math inline">\(SSR_0-SSR = \| P_{A}\varepsilon\|^2 \underset{\mathcal{H}_0}{\sim} \sigma^2 \chi^2(k-k_0)\)</span></li>
<li>Déduisez-en que <span class="math inline">\(F\underset{\mathcal{H}_0}{\sim} \mathcal{F}(k-k_0,n-k)\)</span>.</li>
<li>Montrez que <span class="math inline">\(F\)</span> est indépendante de <span class="math inline">\(Z \widehat{\beta}\)</span> et <span class="math inline">\(\widehat{\beta}\)</span>.</li>
</ul>
</div>
<!--
%On peut également montrer que 
%$$F=\frac{\left(\|\widehat{Y}\|^2-\|\widehat{Y_0}\|^2\right)/q}{\widehat{\sigma^2}}.$$
-->
<p>Cette statistique de test peut s’écrire sous une autre forme donnée dans la proposition suivante :</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-15" class="proposition"><strong>Proposition 4.1  </strong></span>En suivante la première écriture, la statistique de test de Fisher-Snedecor peut également s’écrire sous la forme suivante :
<span class="math display">\[
F=\frac{ [C\widehat{\theta}]&#39; \left[C(X&#39;X)^{-1}C&#39;\right]^{-1} [C\widehat{\theta}] }{q\widehat{\sigma^2}} \textrm{ avec } q=k-k_0.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-16" class="proof"><em>Proof</em>. </span>La preuve de cette proposition est donnée en annexe <a href="preuves-de-quelques-résultats-du-cours.html#ProofFisher">B.1</a>.</p>
</div>
<p>Cette dernière expression a l’avantage de ne pas nécessiter l’estimation du modèle contraint pour tester <span class="math inline">\(\mathcal{H}_0 : C\theta=0_{q}\)</span> contre <span class="math inline">\(\mathcal{H}_1 : C\theta \neq 0_{q}.\)</span></p>
<p>Par la suite, on notera <span class="math inline">\(F^{obs}\)</span> la valeur observée de la statistique de test <span class="math inline">\(F\)</span>.</p>
</div>
<div id="règle-de-décision" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Règle de décision</h3>
<p>La quantité d’importance dans notre construction du test de Fisher est <span class="math inline">\(SSR_0- SSR\)</span>. Intuitivement, si la valeur observée de <span class="math inline">\(SSR_0- SSR\)</span> est très grande, il y a peu de chance que les observations <span class="math inline">\(Y\)</span> soient “issues” du sous-modèle. À l’opposé, si la valeur observée <span class="math inline">\(SSR_0- SSR\)</span> est petite, il est fort possible que le modèle initial puisse être simplifié : le sous-modèle explique aussi bien les observations dans la mesure où <span class="math inline">\(SSR_0\)</span> est comparable à <span class="math inline">\(SSR\)</span>. Par conséquent, la zone de rejet avec un risque de première espèce <span class="math inline">\(\alpha\)</span> s’écrit
<span class="math display">\[
\mathcal{R}_\alpha = \{ F &gt; f_{q,n-k,1-\alpha}\}
\]</span>
où <span class="math inline">\(f_{q,n-k,1-\alpha}\)</span> est le <span class="math inline">\((1-\alpha)\)</span>-quantile de la distribution de Fisher de degrés de liberté <span class="math inline">\(q=k-k_0\)</span> et <span class="math inline">\(n-k\)</span>.</p>
<!--
%\textcolor{red}{ Est-ce-que on laisse ça là ?\\
%\underline{Remarque :} Dans le cadre de la régression linéaire multiple, pour mesurer l'adéquation globale des données au modèle, on définit souvent \textbf{ le coefficient de détermination } $R^2$  par 
%$$
%   R^2=1-\frac{\displaystyle\sum_{i=1}^n(Y_i-\widehat{Y_i})^2}{\displaystyle\sum_{i=1}^n(Y_i-\overline Y)^2}=\frac{\displaystyle\sum_{i=1}^n(\overline Y_i -\widehat{Y})^2}{\displaystyle\sum_{i=1}^n(Y_i-\overline Y)^2}=\frac{\|\widehat{Y} - \overline Y \1_n \|^2}{\| Y -\overline Y \1_n\|^2}.$$
%Intuitivement, nous comprenons bien que lorsque la régression est "précise", alors la variance empirique des résidus est négligeable devant la variance empirique des réponses, donc le coefficient $R^2$ est proche de 1. En reprenant la démonstration précédente, nous remarquons également que le numérateur et le dénominateur de ce coefficient suivent des lois du Khi-deux décentrées et non indépendantes. Le coefficient $R^2$ ne suit donc pas une des lois usuelles simples. De plus, ce coefficient est quelque peu trompeur. En effet, plus nombreux sont les régresseurs utilisés, plus il est proche de 1 et donc plus forte semble l'adéquation du modèle aux données. Pourtant rien ne garantit la légitimité de la présence de chacun des régresseurs. Un test de Fisher sera alors plus probant, en attendant de voir les méthodes de la partie \ref{sélectionmodèle}.
%}
-->
</div>
<div id="comblin" class="section level3">
<h3><span class="header-section-number">4.2.4</span> Cas particulier où <span class="math inline">\(q=1\)</span> : Test de Student</h3>
<p>Dans le cas particulier où l’on teste la nullité d’une seule combinaison linéaire des composantes du paramètre <span class="math inline">\(\theta\)</span>, i.e. <span class="math inline">\(q=1\)</span> et <span class="math inline">\(C \in \mathcal{M}_{1,k}(\mathbb{R})\)</span>, alors l’hypothèse nulle s’écrit :
<span class="math display">\[\mathcal{H}_0 : C\theta=0.\]</span>
On a donc <span class="math inline">\(C(X&#39;X)^{-1}C&#39; \in \mathbb{R}\)</span> et la variable aléatoire <span class="math inline">\(F\)</span> s’écrit alors de la façon suivante :
<span class="math display">\[
    F=\frac{(C\widehat{\theta})^2}{\widehat{\sigma}^2 C(X&#39;X)^{-1}C&#39;}.
\]</span></p>
<p><span class="math inline">\(F\)</span> suit une loi de Fisher à 1 et <span class="math inline">\(n-k\)</span> degrés de liberté. Or une propriété de la distribution de Fisher-Snedecor est qu’une distribution de Fisher-Snedecor à 1 et <span class="math inline">\(m_2\)</span> degrés de liberté est le carré d’une distribution de Student à <span class="math inline">\(m_2\)</span> degrés de liberté. Par conséquent, on obtient l’égalité suivante : si <span class="math inline">\(A\sim \mathcal{F}(1,n-k)\)</span> et <span class="math inline">\(T\sim \mathcal{T}(n-k)\)</span>,
<span class="math display">\[\mathbb{P}\left(A \geq f_{1,n-k,1-\alpha}\right)=\alpha=\mathbb{P}\left(T^2\geq f_{1,n-k,1-\alpha}\right).\]</span>
On en déduit donc la propriété suivante sur les quantiles :
<span class="math display">\[f_{1,n-k,1-\alpha}=t_{n-k,1-\alpha/2}^2.\]</span>
Selon le test de Fisher, on rejette l’hypothèse <span class="math inline">\(\mathcal{H}_0\)</span> si <span class="math inline">\(F \geq f_{1,n-k,1-\alpha}\)</span>. Or on a les équivalences suivantes :</p>
<p><span class="math display">\[\begin{eqnarray*}
F \leq f_{1,n-k,1-\alpha} &amp;\Longleftrightarrow&amp; |C\widehat{\theta}| \leq t_{n-k,1-\alpha/2} \sqrt{\widehat{\sigma}^2C(X&#39;X)^{-1}C&#39;} \\
&amp;\Longleftrightarrow&amp; -t_{n-k,1-\alpha/2} \sqrt{\widehat{\sigma}^2C(X&#39;X)^{-1}C&#39;} \leq C \widehat{\theta} \leq t_{n-k,1-\alpha/2} \sqrt{\widehat{\sigma}^2C(X&#39;X)^{-1}C&#39;}.
\end{eqnarray*}\]</span></p>
<!--Ainsi l'intervalle de confiance au niveau de sécurité $1-\alpha$ de $C\theta$ est 
$$\left[C\widehat{\theta} \pm t_{n-k,1-\alpha/2} \sqrt{\widehat{\sigma}^2C(X'X)^{-1}C'} \right].$$
Au final, le test consiste donc à rejeter l'hypothèse nulle si et seulement si 0 n'appartient pas à l'intervalle de confiance de $C\theta$.-->
<p>Donc au final, on rejette <span class="math inline">\(\mathcal{H}_0\)</span> si <span class="math inline">\(\left| \frac{C\widehat{\theta}} {\sqrt{\widehat{\sigma}^2C(X&#39;X)^{-1}C&#39;}}\right| &gt; t_{n-k,1-\alpha/2}\)</span>. On retrouve le classique test de Student de nullité.</p>
<div class="exercise">
<p><span id="exr:unlabeled-div-17" class="exercise"><strong>Exercise 4.2  </strong></span>Construisez directement le test de Student de nullité du paramètre <span class="math inline">\(\theta_j\)</span> au niveau <span class="math inline">\(\alpha\)</span>.</p>
</div>
<!--
%\subsection{Rappels : méthodologie des tests}
%À ce stade, il semble important de rappeler quelques éléments méthodologiques associés à la théorie des tests.
%
%De manière générale, le statisticien aime bien rejeter l'hypothèse $\Hc_0$ : cela signifie que non seulement nous avons mis de l'information en évidence mais également que la probabilité de se tromper est assez faible (contrôlée par l'erreur de première espèce). L'hypothèse $\Hc_0$ est en effet souvent conservative au sens où elle fait appel à des modèles assez simples. 
%
%Le fait de ne pas rejeter $\Hc_0$ est beaucoup plus problématique dans la mesure où l'erreur de seconde espèce n'est presque jamais calculable : seule la fonction puissance est éventuellement disponible. La question naturelle à se poser est donc de savoir si le non rejet de $\Hc_0$ est dû à la réalité de cette hypothèse... ou à l'insuffisance d'information pour pouvoir mettre en évidence $\Hc_1$. Dans ce contexte, de nombreux statisticiens préfèrent \textit{ne pas rejeter} $\Hc_0$ plutôt que l'\textit{accepter}.
%
%Un autre point important concerne l'interprétation éventuelle pouvant être mise en place suite au non rejet de $\Hc_0$. Pour simplifier, nous nous plaçons dans un contexte de régression linéaire simple et nous nous intéressons à la valeur de la pente $\Hc_0: b=0$. Rejeter $\Hc_0$ revient à dire que la pente $b$ de la droite est significativement non nulle. La variable de réponse et celle de régression sont donc corrélées. Il ne faut cependant pas confondre \textit{corrélation} et \textit{relation de cause à effet}.
-->
</div>
</div>
<div id="intervalle-région-de-confiance-pour-ctheta" class="section level2">
<h2><span class="header-section-number">4.3</span> Intervalle (région) de confiance pour <span class="math inline">\(C\theta\)</span></h2>
<div id="ic-pour-ctheta-in-mathbbr" class="section level3">
<h3><span class="header-section-number">4.3.1</span> IC pour <span class="math inline">\(C\theta \in \mathbb{R}\)</span></h3>
<p>Commençons par l’intervalle de confiance pour une combinaison linéaire <span class="math inline">\(C\theta \in \mathbb{R}\)</span>. Nous reprenons les notations de la section <a href="Test.html#comblin">4.2.4</a>.
Comme <span class="math inline">\(\widehat{\theta}\sim\mathcal{N}_k(\theta,\sigma^2 (X&#39;X)^{-1})\)</span>, on a <span class="math inline">\(C\widehat{\theta} \sim\mathcal{N}(C \theta,\sigma^2 \Delta)\)</span> avec <span class="math inline">\(\Delta=C(X&#39;X)^{-1} C&#39; \in\mathbb{R}\)</span>. De plus <span class="math inline">\((n-k)\widehat{\sigma}^2 / \sigma^2 \sim \chi^2(n-k)\)</span> et <span class="math inline">\(\widehat{\theta}\)</span> et <span class="math inline">\(\widehat{\sigma}^2\)</span> sont indépendantes. Ainsi,
<span class="math display">\[
\frac{C\widehat{\theta} - C\theta}{\widehat{\sigma} \sqrt{\Delta}} \sim \mathcal{T}(n-k).
\]</span>
On obtient ainsi l’intervalle de confiance suivant au niveau de confiance <span class="math inline">\(1-\alpha\)</span> :
<span class="math display">\[
IC_{1-\alpha}(C\theta)=\left[C\widehat{\theta} \pm t_{n-k,1-\alpha/2}\sqrt{\widehat{\sigma}^2 C (X&#39;X)^{-1} C&#39;}\right].
\]</span>
Rappelons le lien entre test et intervalle de confiance : l’ensemble des <span class="math inline">\(c_0\)</span> acceptés pour un test
<span class="math display">\[
\mathcal{H}_0 : C\theta = c_0 \textrm{  contre  } \mathcal{H}_1 : C\theta \neq c_0
\]</span>
au niveau <span class="math inline">\(\alpha\)</span>, définit un intervalle de confiance au niveau de confiance <span class="math inline">\(1-\alpha\)</span>.</p>
</div>
<div id="région-de-confiance-pour-ctheta-in-mathbbrq" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Région de confiance pour <span class="math inline">\(C\theta \in \mathbb{R}^q\)</span></h3>
<p>Si maintenant, comme dans la partie <a href="Test.html#comblinconjointes">4.2.2</a>, <span class="math inline">\(C\theta\)</span> est de dimension <span class="math inline">\(q&gt;1\)</span> et si <span class="math inline">\(c_0\)</span> est une valeur particulière appartenant à <span class="math inline">\(\mathbb{R}^q\)</span>, nous pouvons généraliser la construction de l’intervalle de confiance.
Dans ce cas, <span class="math inline">\(C\widehat{\theta} - C\theta \sim \mathcal{N}_q(0_q,\sigma^2 \Delta)\)</span> avec <span class="math inline">\(\Delta = C(X&#39;X)^{-1} C&#39; \in \mathcal{M}_q(\mathbb{R})\)</span>. Ainsi
<span class="math display">\[
\frac{[C\widehat{\theta} - C\theta] &#39;  \Delta^{-1} [C\widehat{\theta} - C\theta]}{\sigma^2} \sim \chi^2(q).
\]</span>
On a aussi <span class="math inline">\((n-k)\widehat{\sigma}^2 / \sigma^2 \sim \chi^2(n-k)\)</span> et les deux statistiques sont indépendantes. On en déduit donc que
<span class="math display">\[
A:= \frac{[C\widehat{\theta} - C\theta] &#39;  \Delta^{-1} [C\widehat{\theta} - C\theta]}{q\ \widehat{\sigma}^2} \sim \mathcal{F}(q,n-k).
\]</span>
Finalement,
<span class="math display">\[\begin{eqnarray*}
&amp; &amp;\mathbb{P}(A\leq  f_{q,n-k,1-\alpha} ) = 1-\alpha\\
\Leftrightarrow&amp; &amp;\mathbb{P}([C\widehat{\theta} - C\theta] &#39;  \Delta^{-1} [C\widehat{\theta} - C\theta] \leq q \widehat{\sigma}^2  f_{q,n-k,1-\alpha} ) = 1-\alpha\\
\Leftrightarrow&amp; &amp; \mathbb{P}(C\theta \in RC) = 1 - \alpha
\end{eqnarray*}\]</span>
où <span class="math inline">\(RC\)</span> est l’ellipsoïde de confiance défini par :
<span class="math display">\[ RC= \left\{u \in \mathbb{R}^q; \, (C \widehat{\theta} -u )&#39; [C (X&#39; X)^{-1} C&#39;]^{-1} (C \widehat{\theta}- u) \leq q \widehat{\sigma}^2 f_{q,n-k,1-\alpha}\right\}.\]</span></p>
<p>L’ensemble des <span class="math inline">\(c_0\in\mathbb{R}^q\)</span> acceptés par le test
<span class="math display">\[
\mathcal{H}_0 :  C \theta=c_0 \textrm{  contre  } \mathcal{H}_1 : C \theta \neq c_0
\]</span>
au niveau <span class="math inline">\(\alpha\)</span> forme l’ellipsoïde de confiance <span class="math inline">\(RC\)</span> défini ci-dessus.</p>
</div>
</div>
<div id="en-résumé-2" class="section level2">
<h2><span class="header-section-number">4.4</span> En résumé</h2>
<div class="summarybox">
<ul>
<li>Savoir écrire les hypothèses d’un test de Fisher de sous-modèle</li>
<li>Savoir justifier qu’un modèle est sous-modèle d’un autre</li>
<li>Connaitre la forme de la statistique du test de Fisher, sa loi sous <span class="math inline">\(\mathcal{H}_0\)</span> et savoir définir les quantités qui la composent selon le contexte (Théorème <a href="Test.html#thm:TestF">4.1</a>)</li>
<li>Savoir mener la construction d’un test de Fisher de sous-modèle</li>
<li>Savoir mener la construction d’un test de Student quand <span class="math inline">\(q=1\)</span></li>
<li>Savoir mener la construction d’un intervalle de confiance pour <span class="math inline">\(C\theta\)</span>. 
Ne pas apprendre la formule !</li>
</ul>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="EstML.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="singulier.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Bookdown-poly.pdf", "Bookdown-poly.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
