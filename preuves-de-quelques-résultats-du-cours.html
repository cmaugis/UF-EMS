<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>B Preuves de quelques résultats du cours | Modèle linéaire général et modèle linéaire généralisé</title>
  <meta name="description" content="B Preuves de quelques résultats du cours | Modèle linéaire général et modèle linéaire généralisé" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="B Preuves de quelques résultats du cours | Modèle linéaire général et modèle linéaire généralisé" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="B Preuves de quelques résultats du cours | Modèle linéaire général et modèle linéaire généralisé" />
  
  
  

<meta name="author" content="Cathy Maugis-Rabusseau (INSA Toulouse / IMT)" />


<meta name="date" content="2021-10-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="rappels-de-probabilités-statistiques-et-doptimisation.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">UF Elements de modélisation statistique</a></li>
<li>      <img src="image/LogoInsaToulouse.jpg" height="20px" align="right"/>      </li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Préface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#modélisation-dune-réponse-quantitative"><i class="fa fa-check"></i><b>1.1</b> Modélisation d’une réponse quantitative</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#jeu-de-données-illustratif"><i class="fa fa-check"></i><b>1.1.1</b> Jeu de données illustratif</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#régression-linéaire"><i class="fa fa-check"></i><b>1.1.2</b> Régression linéaire</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#analyse-de-la-variance-anova"><i class="fa fa-check"></i><b>1.1.3</b> Analyse de la variance (ANOVA)</a></li>
<li class="chapter" data-level="1.1.4" data-path="intro.html"><a href="intro.html#analyse-de-covariance-ancova"><i class="fa fa-check"></i><b>1.1.4</b> Analyse de covariance (ANCOVA)</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#modélisation-dune-variable-binaire-de-comptage"><i class="fa fa-check"></i><b>1.2</b> Modélisation d’une variable binaire, de comptage, …</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#objectifs-du-cours"><i class="fa fa-check"></i><b>1.3</b> Objectifs du cours</a></li>
</ul></li>
<li class="part"><span><b>I Le modèle linéaire général</b></span></li>
<li class="chapter" data-level="2" data-path="DefML.html"><a href="DefML.html"><i class="fa fa-check"></i><b>2</b> Définitions générales</a><ul>
<li class="chapter" data-level="2.1" data-path="DefML.html"><a href="DefML.html#modlinreg"><i class="fa fa-check"></i><b>2.1</b> Modèle linéaire régulier</a></li>
<li class="chapter" data-level="2.2" data-path="DefML.html"><a href="DefML.html#exemples-de-modèle-linéaire-gaussien"><i class="fa fa-check"></i><b>2.2</b> Exemples de modèle linéaire gaussien</a><ul>
<li class="chapter" data-level="2.2.1" data-path="DefML.html"><a href="DefML.html#le-modèle-de-régression-linéaire"><i class="fa fa-check"></i><b>2.2.1</b> Le modèle de régression linéaire</a></li>
<li class="chapter" data-level="2.2.2" data-path="DefML.html"><a href="DefML.html#le-modèle-danalyse-de-la-variance"><i class="fa fa-check"></i><b>2.2.2</b> Le modèle d’analyse de la variance</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="DefML.html"><a href="DefML.html#en-résumé"><i class="fa fa-check"></i><b>2.3</b> En résumé</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="EstML.html"><a href="EstML.html"><i class="fa fa-check"></i><b>3</b> Estimation des paramètres</a><ul>
<li class="chapter" data-level="3.1" data-path="EstML.html"><a href="EstML.html#estimation-de-theta"><i class="fa fa-check"></i><b>3.1</b> Estimation de <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="3.2" data-path="EstML.html"><a href="EstML.html#valeurs-ajustées-et-résidus"><i class="fa fa-check"></i><b>3.2</b> Valeurs ajustées et résidus</a></li>
<li class="chapter" data-level="3.3" data-path="EstML.html"><a href="EstML.html#estimation-de-sigma2"><i class="fa fa-check"></i><b>3.3</b> Estimation de <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="3.4" data-path="EstML.html"><a href="EstML.html#erreurs-standards"><i class="fa fa-check"></i><b>3.4</b> Erreurs standards</a></li>
<li class="chapter" data-level="3.5" data-path="EstML.html"><a href="EstML.html#intervalle-de-confiance-de-theta_j-de-xtheta_i-et-de-x_0theta"><i class="fa fa-check"></i><b>3.5</b> Intervalle de confiance de <span class="math inline">\(\theta_j\)</span>, de <span class="math inline">\((X\theta)_i\)</span> et de <span class="math inline">\(X_0\theta\)</span></a><ul>
<li class="chapter" data-level="3.5.1" data-path="EstML.html"><a href="EstML.html#ICthetaj"><i class="fa fa-check"></i><b>3.5.1</b> Intervalle de confiance de <span class="math inline">\(\theta_j\)</span></a></li>
<li class="chapter" data-level="3.5.2" data-path="EstML.html"><a href="EstML.html#ICXthetai"><i class="fa fa-check"></i><b>3.5.2</b> Intervalle de confiance de <span class="math inline">\((X\theta)_i\)</span></a></li>
<li class="chapter" data-level="3.5.3" data-path="EstML.html"><a href="EstML.html#ICX0theta"><i class="fa fa-check"></i><b>3.5.3</b> Intervalle de confiance de <span class="math inline">\(X_0\theta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="EstML.html"><a href="EstML.html#ICpredit"><i class="fa fa-check"></i><b>3.6</b> Intervalles de prédiction</a></li>
<li class="chapter" data-level="3.7" data-path="EstML.html"><a href="EstML.html#qualité-dajustement"><i class="fa fa-check"></i><b>3.7</b> Qualité d’ajustement</a></li>
<li class="chapter" data-level="3.8" data-path="EstML.html"><a href="EstML.html#en-résumé-1"><i class="fa fa-check"></i><b>3.8</b> En résumé</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Test.html"><a href="Test.html"><i class="fa fa-check"></i><b>4</b> Test de Fisher-Snedecor</a><ul>
<li class="chapter" data-level="4.1" data-path="Test.html"><a href="Test.html#hypothèses-testées"><i class="fa fa-check"></i><b>4.1</b> Hypothèses testées</a><ul>
<li class="chapter" data-level="4.1.1" data-path="Test.html"><a href="Test.html#première-écriture"><i class="fa fa-check"></i><b>4.1.1</b> Première écriture</a></li>
<li class="chapter" data-level="4.1.2" data-path="Test.html"><a href="Test.html#seconde-écriture"><i class="fa fa-check"></i><b>4.1.2</b> Seconde écriture</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="Test.html"><a href="Test.html#le-test-de-fisher-snedecor"><i class="fa fa-check"></i><b>4.2</b> Le test de Fisher-Snedecor</a><ul>
<li class="chapter" data-level="4.2.1" data-path="Test.html"><a href="Test.html#principe"><i class="fa fa-check"></i><b>4.2.1</b> Principe</a></li>
<li class="chapter" data-level="4.2.2" data-path="Test.html"><a href="Test.html#comblinconjointes"><i class="fa fa-check"></i><b>4.2.2</b> La statistique de test</a></li>
<li class="chapter" data-level="4.2.3" data-path="Test.html"><a href="Test.html#règle-de-décision"><i class="fa fa-check"></i><b>4.2.3</b> Règle de décision</a></li>
<li class="chapter" data-level="4.2.4" data-path="Test.html"><a href="Test.html#comblin"><i class="fa fa-check"></i><b>4.2.4</b> Cas particulier où <span class="math inline">\(q=1\)</span> : Test de Student</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="Test.html"><a href="Test.html#intervalle-région-de-confiance-pour-ctheta"><i class="fa fa-check"></i><b>4.3</b> Intervalle (région) de confiance pour <span class="math inline">\(C\theta\)</span></a><ul>
<li class="chapter" data-level="4.3.1" data-path="Test.html"><a href="Test.html#ic-pour-ctheta-in-mathbbr"><i class="fa fa-check"></i><b>4.3.1</b> IC pour <span class="math inline">\(C\theta \in \mathbb{R}\)</span></a></li>
<li class="chapter" data-level="4.3.2" data-path="Test.html"><a href="Test.html#région-de-confiance-pour-ctheta-in-mathbbrq"><i class="fa fa-check"></i><b>4.3.2</b> Région de confiance pour <span class="math inline">\(C\theta \in \mathbb{R}^q\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="Test.html"><a href="Test.html#en-résumé-2"><i class="fa fa-check"></i><b>4.4</b> En résumé</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="singulier.html"><a href="singulier.html"><i class="fa fa-check"></i><b>5</b> Modèles singuliers, orthogonalité et importance des hypothèses sur les erreurs</a><ul>
<li class="chapter" data-level="5.1" data-path="singulier.html"><a href="singulier.html#quand-h1-h4-ne-sont-pas-respectées"><i class="fa fa-check"></i><b>5.1</b> Quand H1-H4 ne sont pas respectées…</a><ul>
<li class="chapter" data-level="5.1.1" data-path="singulier.html"><a href="singulier.html#propriétés-de-lestimateur-des-moindres-carrés-widehattheta"><i class="fa fa-check"></i><b>5.1.1</b> Propriétés de l’estimateur des moindres carrés <span class="math inline">\(\widehat{\theta}\)</span></a></li>
<li class="chapter" data-level="5.1.2" data-path="singulier.html"><a href="singulier.html#propriétés-de-lestimateur-des-moindres-carrés-widehatsigma2"><i class="fa fa-check"></i><b>5.1.2</b> Propriétés de l’estimateur des moindres carrés <span class="math inline">\(\widehat{\sigma}^2\)</span></a></li>
<li class="chapter" data-level="5.1.3" data-path="singulier.html"><a href="singulier.html#modèles-avec-corrélations"><i class="fa fa-check"></i><b>5.1.3</b> Modèles avec corrélations</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="singulier.html"><a href="singulier.html#ModSingulier"><i class="fa fa-check"></i><b>5.2</b> Modèles singuliers</a><ul>
<li class="chapter" data-level="5.2.1" data-path="singulier.html"><a href="singulier.html#contraintes-didentifiabilité"><i class="fa fa-check"></i><b>5.2.1</b> Contraintes d’identifiabilité</a></li>
<li class="chapter" data-level="5.2.2" data-path="singulier.html"><a href="singulier.html#fonctions-estimables-et-contrastes"><i class="fa fa-check"></i><b>5.2.2</b> Fonctions estimables et contrastes</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="singulier.html"><a href="singulier.html#orthogonalité"><i class="fa fa-check"></i><b>5.3</b> Orthogonalité</a><ul>
<li class="chapter" data-level="5.3.1" data-path="singulier.html"><a href="singulier.html#orthogonalité-pour-les-modèles-réguliers"><i class="fa fa-check"></i><b>5.3.1</b> Orthogonalité pour les modèles réguliers</a></li>
<li class="chapter" data-level="5.3.2" data-path="singulier.html"><a href="singulier.html#orthogonalité-pour-les-modèles-non-réguliers"><i class="fa fa-check"></i><b>5.3.2</b> Orthogonalité pour les modèles non-réguliers</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="singulier.html"><a href="singulier.html#en-résumé-3"><i class="fa fa-check"></i><b>5.4</b> En résumé</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>6</b> La régression linéaire</a><ul>
<li class="chapter" data-level="6.1" data-path="regression.html"><a href="regression.html#introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a><ul>
<li class="chapter" data-level="6.1.1" data-path="regression.html"><a href="regression.html#exemple-illustratif"><i class="fa fa-check"></i><b>6.1.1</b> Exemple illustratif</a></li>
<li class="chapter" data-level="6.1.2" data-path="regression.html"><a href="regression.html#problématique"><i class="fa fa-check"></i><b>6.1.2</b> Problématique</a></li>
<li class="chapter" data-level="6.1.3" data-path="regression.html"><a href="regression.html#le-modèle-de-régression-linéaire-simple"><i class="fa fa-check"></i><b>6.1.3</b> Le modèle de régression linéaire simple</a></li>
<li class="chapter" data-level="6.1.4" data-path="regression.html"><a href="regression.html#le-modèle-de-régression-linéaire-multiple"><i class="fa fa-check"></i><b>6.1.4</b> Le modèle de régression linéaire multiple</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="regression.html"><a href="regression.html#estimation"><i class="fa fa-check"></i><b>6.2</b> Estimation</a><ul>
<li class="chapter" data-level="6.2.1" data-path="regression.html"><a href="regression.html#résultats-généraux"><i class="fa fa-check"></i><b>6.2.1</b> Résultats généraux</a></li>
<li class="chapter" data-level="6.2.2" data-path="regression.html"><a href="regression.html#propriétés-en-régression-linéaire-simple"><i class="fa fa-check"></i><b>6.2.2</b> Propriétés en régression linéaire simple</a></li>
<li class="chapter" data-level="6.2.3" data-path="regression.html"><a href="regression.html#le-coefficient-r2"><i class="fa fa-check"></i><b>6.2.3</b> Le coefficient <span class="math inline">\(R^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="regression.html"><a href="regression.html#tests-et-intervalles-de-confiance"><i class="fa fa-check"></i><b>6.3</b> Tests et intervalles de confiance</a><ul>
<li class="chapter" data-level="6.3.1" data-path="regression.html"><a href="regression.html#test-de-nullité-dun-paramètre-du-modèle"><i class="fa fa-check"></i><b>6.3.1</b> Test de nullité d’un paramètre du modèle</a></li>
<li class="chapter" data-level="6.3.2" data-path="regression.html"><a href="regression.html#test-de-nullité-de-quelques-paramètres-du-modèle"><i class="fa fa-check"></i><b>6.3.2</b> Test de nullité de quelques paramètres du modèle</a></li>
<li class="chapter" data-level="6.3.3" data-path="regression.html"><a href="regression.html#test-de-nullité-de-tous-les-paramètres-du-modèle"><i class="fa fa-check"></i><b>6.3.3</b> Test de nullité de tous les paramètres du modèle</a></li>
<li class="chapter" data-level="6.3.4" data-path="regression.html"><a href="regression.html#intervalle-de-confiance-de-theta_j-de-xtheta_i-et-de-x_0theta-1"><i class="fa fa-check"></i><b>6.3.4</b> Intervalle de confiance de <span class="math inline">\(\theta_j\)</span>, de <span class="math inline">\((X\theta)_i\)</span> et de <span class="math inline">\(X_0\theta\)</span></a></li>
<li class="chapter" data-level="6.3.5" data-path="regression.html"><a href="regression.html#intervalle-de-prédiction"><i class="fa fa-check"></i><b>6.3.5</b> Intervalle de prédiction</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="regression.html"><a href="regression.html#sélection-des-variables-explicatives"><i class="fa fa-check"></i><b>6.4</b> Sélection des variables explicatives</a><ul>
<li class="chapter" data-level="6.4.1" data-path="regression.html"><a href="regression.html#cadre-général-de-sélection-de-modèles"><i class="fa fa-check"></i><b>6.4.1</b> Cadre général de sélection de modèles</a></li>
<li class="chapter" data-level="6.4.2" data-path="regression.html"><a href="regression.html#quelques-critères-pour-sélectionner-un-modèle"><i class="fa fa-check"></i><b>6.4.2</b> Quelques critères pour sélectionner un modèle</a></li>
<li class="chapter" data-level="6.4.3" data-path="regression.html"><a href="regression.html#algorithmes-de-sélection-de-variables"><i class="fa fa-check"></i><b>6.4.3</b> Algorithmes de sélection de variables</a></li>
<li class="chapter" data-level="6.4.4" data-path="regression.html"><a href="regression.html#illustration-sur-lexemple"><i class="fa fa-check"></i><b>6.4.4</b> Illustration sur l’exemple</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="regression.html"><a href="regression.html#régression-linéaire-régularisée"><i class="fa fa-check"></i><b>6.5</b> Régression linéaire régularisée</a><ul>
<li class="chapter" data-level="6.5.1" data-path="regression.html"><a href="regression.html#régression-ridge"><i class="fa fa-check"></i><b>6.5.1</b> Régression ridge</a></li>
<li class="chapter" data-level="6.5.2" data-path="regression.html"><a href="regression.html#régression-lasso"><i class="fa fa-check"></i><b>6.5.2</b> Régression Lasso</a></li>
<li class="chapter" data-level="6.5.3" data-path="regression.html"><a href="regression.html#régression-elastic-net"><i class="fa fa-check"></i><b>6.5.3</b> Régression Elastic-Net</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="regression.html"><a href="regression.html#ValidationMod"><i class="fa fa-check"></i><b>6.6</b> Validation du modèle</a><ul>
<li class="chapter" data-level="6.6.1" data-path="regression.html"><a href="regression.html#contrôle-graphique-a-posteriori"><i class="fa fa-check"></i><b>6.6.1</b> Contrôle graphique a posteriori</a></li>
<li class="chapter" data-level="6.6.2" data-path="regression.html"><a href="regression.html#pour-vérifier-les-hypothèses-h1-et-h2-adéquation-et-homoscédasticité"><i class="fa fa-check"></i><b>6.6.2</b> Pour vérifier les hypothèses H1 et H2 : adéquation et homoscédasticité</a></li>
<li class="chapter" data-level="6.6.3" data-path="regression.html"><a href="regression.html#pour-vérifier-lhypothèse-h3-indépendance"><i class="fa fa-check"></i><b>6.6.3</b> Pour vérifier l’hypothèse H3 : indépendance</a></li>
<li class="chapter" data-level="6.6.4" data-path="regression.html"><a href="regression.html#pour-vérifier-lhypothèse-h4-gaussianité"><i class="fa fa-check"></i><b>6.6.4</b> Pour vérifier l’hypothèse H4 : gaussianité</a></li>
<li class="chapter" data-level="6.6.5" data-path="regression.html"><a href="regression.html#détection-de-données-aberrantes"><i class="fa fa-check"></i><b>6.6.5</b> Détection de données aberrantes</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="regression.html"><a href="regression.html#en-résumé-4"><i class="fa fa-check"></i><b>6.7</b> En résumé</a></li>
<li class="chapter" data-level="6.8" data-path="regression.html"><a href="regression.html#quelques-codes-python"><i class="fa fa-check"></i><b>6.8</b> Quelques codes python</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ANOVA.html"><a href="ANOVA.html"><i class="fa fa-check"></i><b>7</b> Analyse de variance (ANOVA)</a><ul>
<li class="chapter" data-level="7.1" data-path="ANOVA.html"><a href="ANOVA.html#vocabulaire"><i class="fa fa-check"></i><b>7.1</b> Vocabulaire</a></li>
<li class="chapter" data-level="7.2" data-path="ANOVA.html"><a href="ANOVA.html#analyse-de-variance-à-un-facteur"><i class="fa fa-check"></i><b>7.2</b> Analyse de variance à un facteur</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ANOVA.html"><a href="ANOVA.html#exemple-et-notations"><i class="fa fa-check"></i><b>7.2.1</b> Exemple et notations</a></li>
<li class="chapter" data-level="7.2.2" data-path="ANOVA.html"><a href="ANOVA.html#modèle-régulier"><i class="fa fa-check"></i><b>7.2.2</b> Modèle régulier</a></li>
<li class="chapter" data-level="7.2.3" data-path="ANOVA.html"><a href="ANOVA.html#modèle-singulier"><i class="fa fa-check"></i><b>7.2.3</b> Modèle singulier</a></li>
<li class="chapter" data-level="7.2.4" data-path="ANOVA.html"><a href="ANOVA.html#prédictions-résidus-et-variance"><i class="fa fa-check"></i><b>7.2.4</b> Prédictions, résidus et variance</a></li>
<li class="chapter" data-level="7.2.5" data-path="ANOVA.html"><a href="ANOVA.html#intervalle-de-confiance-et-test-sur-leffet-facteur"><i class="fa fa-check"></i><b>7.2.5</b> Intervalle de confiance et test sur l’effet facteur</a></li>
<li class="chapter" data-level="7.2.6" data-path="ANOVA.html"><a href="ANOVA.html#test-deffet-du-facteur"><i class="fa fa-check"></i><b>7.2.6</b> Test d’effet du facteur</a></li>
<li class="chapter" data-level="7.2.7" data-path="ANOVA.html"><a href="ANOVA.html#tableau-danalyse-de-la-variance-à-un-facteur"><i class="fa fa-check"></i><b>7.2.7</b> Tableau d’analyse de la variance à un facteur</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ANOVA.html"><a href="ANOVA.html#analyse-de-variance-à-deux-facteurs"><i class="fa fa-check"></i><b>7.3</b> Analyse de variance à deux facteurs</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ANOVA.html"><a href="ANOVA.html#notations-et-exemple"><i class="fa fa-check"></i><b>7.3.1</b> Notations et exemple</a></li>
<li class="chapter" data-level="7.3.2" data-path="ANOVA.html"><a href="ANOVA.html#modélisation"><i class="fa fa-check"></i><b>7.3.2</b> Modélisation</a></li>
<li class="chapter" data-level="7.3.3" data-path="ANOVA.html"><a href="ANOVA.html#estimation-des-paramètres"><i class="fa fa-check"></i><b>7.3.3</b> Estimation des paramètres</a></li>
<li class="chapter" data-level="7.3.4" data-path="ANOVA.html"><a href="ANOVA.html#prédiction-résidus-et-variance"><i class="fa fa-check"></i><b>7.3.4</b> Prédiction, résidus et variance</a></li>
<li class="chapter" data-level="7.3.5" data-path="ANOVA.html"><a href="ANOVA.html#décomposition-de-la-variabilité"><i class="fa fa-check"></i><b>7.3.5</b> Décomposition de la variabilité</a></li>
<li class="chapter" data-level="7.3.6" data-path="ANOVA.html"><a href="ANOVA.html#le-diagramme-dinteractions"><i class="fa fa-check"></i><b>7.3.6</b> Le diagramme d’interactions</a></li>
<li class="chapter" data-level="7.3.7" data-path="ANOVA.html"><a href="ANOVA.html#tests-dhypothèses"><i class="fa fa-check"></i><b>7.3.7</b> Tests d’hypothèses</a></li>
<li class="chapter" data-level="7.3.8" data-path="ANOVA.html"><a href="ANOVA.html#test-dabsence-deffet-du-facteur-b"><i class="fa fa-check"></i><b>7.3.8</b> Test d’absence d’effet du facteur <span class="math inline">\(B\)</span></a></li>
<li class="chapter" data-level="7.3.9" data-path="ANOVA.html"><a href="ANOVA.html#tableau-danalyse-de-variance-à-deux-facteurs-croisés-dans-le-cas-dun-plan-orthogonal"><i class="fa fa-check"></i><b>7.3.9</b> Tableau d’analyse de variance à deux facteurs croisés dans le cas d’un plan orthogonal</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ANOVA.html"><a href="ANOVA.html#en-résumé-5"><i class="fa fa-check"></i><b>7.4</b> En résumé</a></li>
<li class="chapter" data-level="7.5" data-path="ANOVA.html"><a href="ANOVA.html#quelques-codes-en-python"><i class="fa fa-check"></i><b>7.5</b> Quelques codes en python</a><ul>
<li class="chapter" data-level="7.5.1" data-path="ANOVA.html"><a href="ANOVA.html#exemple-danova-à-un-facteur"><i class="fa fa-check"></i><b>7.5.1</b> Exemple d’ANOVA à un facteur</a></li>
<li class="chapter" data-level="7.5.2" data-path="ANOVA.html"><a href="ANOVA.html#exemple-danova-à-deux-facteurs"><i class="fa fa-check"></i><b>7.5.2</b> Exemple d’ANOVA à deux facteurs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ANCOVA.html"><a href="ANCOVA.html"><i class="fa fa-check"></i><b>8</b> Analyse de covariance (ANCOVA)</a><ul>
<li class="chapter" data-level="8.1" data-path="ANCOVA.html"><a href="ANCOVA.html#les-données"><i class="fa fa-check"></i><b>8.1</b> Les données</a></li>
<li class="chapter" data-level="8.2" data-path="ANCOVA.html"><a href="ANCOVA.html#modélisation-1"><i class="fa fa-check"></i><b>8.2</b> Modélisation</a><ul>
<li class="chapter" data-level="8.2.1" data-path="ANCOVA.html"><a href="ANCOVA.html#modélisation-régulière"><i class="fa fa-check"></i><b>8.2.1</b> Modélisation régulière</a></li>
<li class="chapter" data-level="8.2.2" data-path="ANCOVA.html"><a href="ANCOVA.html#modélisation-singulière"><i class="fa fa-check"></i><b>8.2.2</b> Modélisation singulière</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ANCOVA.html"><a href="ANCOVA.html#estimation-des-paramètres-1"><i class="fa fa-check"></i><b>8.3</b> Estimation des paramètres</a></li>
<li class="chapter" data-level="8.4" data-path="ANCOVA.html"><a href="ANCOVA.html#tests-dhypothèses-1"><i class="fa fa-check"></i><b>8.4</b> Tests d’hypothèses</a><ul>
<li class="chapter" data-level="8.4.1" data-path="ANCOVA.html"><a href="ANCOVA.html#absence-de-tout-effet"><i class="fa fa-check"></i><b>8.4.1</b> Absence de tout effet</a></li>
<li class="chapter" data-level="8.4.2" data-path="ANCOVA.html"><a href="ANCOVA.html#test-dabsence-dinteraction"><i class="fa fa-check"></i><b>8.4.2</b> Test d’absence d’interaction</a></li>
<li class="chapter" data-level="8.4.3" data-path="ANCOVA.html"><a href="ANCOVA.html#test-dabsence-de-leffet-de-la-covariable-z"><i class="fa fa-check"></i><b>8.4.3</b> Test d’absence de l’effet de la covariable z</a></li>
<li class="chapter" data-level="8.4.4" data-path="ANCOVA.html"><a href="ANCOVA.html#test-dabsence-de-leffet-facteur-t"><i class="fa fa-check"></i><b>8.4.4</b> Test d’absence de l’effet facteur T</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ANCOVA.html"><a href="ANCOVA.html#en-résumé-6"><i class="fa fa-check"></i><b>8.5</b> En résumé</a></li>
<li class="chapter" data-level="8.6" data-path="ANCOVA.html"><a href="ANCOVA.html#quelques-codes-en-python-1"><i class="fa fa-check"></i><b>8.6</b> Quelques codes en python</a></li>
</ul></li>
<li class="part"><span><b>II Le modèle linéaire généralisé</b></span></li>
<li class="chapter" data-level="9" data-path="GLM.html"><a href="GLM.html"><i class="fa fa-check"></i><b>9</b> Principe du modèle linéaire généralisé</a><ul>
<li class="chapter" data-level="9.1" data-path="GLM.html"><a href="GLM.html#introduction-1"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="GLM.html"><a href="GLM.html#caractérisation-dun-modèle-linéaire-généralisé"><i class="fa fa-check"></i><b>9.2</b> Caractérisation d’un modèle linéaire généralisé</a><ul>
<li class="chapter" data-level="9.2.1" data-path="GLM.html"><a href="GLM.html#loi-de-la-variable-réponse-y"><i class="fa fa-check"></i><b>9.2.1</b> Loi de la variable réponse <span class="math inline">\(Y\)</span></a></li>
<li class="chapter" data-level="9.2.2" data-path="GLM.html"><a href="GLM.html#prédicteur-linéaire"><i class="fa fa-check"></i><b>9.2.2</b> Prédicteur linéaire</a></li>
<li class="chapter" data-level="9.2.3" data-path="GLM.html"><a href="GLM.html#fonction-de-lien"><i class="fa fa-check"></i><b>9.2.3</b> Fonction de lien</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="GLM.html"><a href="GLM.html#EstimMLG"><i class="fa fa-check"></i><b>9.3</b> Estimation</a><ul>
<li class="chapter" data-level="9.3.1" data-path="GLM.html"><a href="GLM.html#estimation-par-maximum-de-vraisemblance"><i class="fa fa-check"></i><b>9.3.1</b> Estimation par maximum de vraisemblance</a></li>
<li class="chapter" data-level="9.3.2" data-path="GLM.html"><a href="GLM.html#algorithmes-de-newton-raphson-et-fisher-scoring"><i class="fa fa-check"></i><b>9.3.2</b> Algorithmes de Newton-Raphson et Fisher-scoring</a></li>
<li class="chapter" data-level="9.3.3" data-path="GLM.html"><a href="GLM.html#equations-de-vraisemblance"><i class="fa fa-check"></i><b>9.3.3</b> Equations de vraisemblance</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="GLM.html"><a href="GLM.html#NormalitéAsymptotique"><i class="fa fa-check"></i><b>9.4</b> Loi asymptotique de l’EMV et inférence</a></li>
<li class="chapter" data-level="9.5" data-path="GLM.html"><a href="GLM.html#tests-dhypothèses-2"><i class="fa fa-check"></i><b>9.5</b> Tests d’hypothèses</a><ul>
<li class="chapter" data-level="9.5.1" data-path="GLM.html"><a href="GLM.html#test-de-modèles-emboîtés"><i class="fa fa-check"></i><b>9.5.1</b> Test de modèles emboîtés</a></li>
<li class="chapter" data-level="9.5.2" data-path="GLM.html"><a href="GLM.html#TestParamMLG"><i class="fa fa-check"></i><b>9.5.2</b> Test d’un paramètre <span class="math inline">\(\theta_j\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="GLM.html"><a href="GLM.html#MLGIC"><i class="fa fa-check"></i><b>9.6</b> Intervalle de confiance pour <span class="math inline">\(\theta_j\)</span></a><ul>
<li class="chapter" data-level="9.6.1" data-path="GLM.html"><a href="GLM.html#par-wald"><i class="fa fa-check"></i><b>9.6.1</b> Par Wald</a></li>
<li class="chapter" data-level="9.6.2" data-path="GLM.html"><a href="GLM.html#fondé-sur-le-rapport-de-vraisemblances"><i class="fa fa-check"></i><b>9.6.2</b> Fondé sur le rapport de vraisemblances</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="GLM.html"><a href="GLM.html#qualité-dajustement-1"><i class="fa fa-check"></i><b>9.7</b> Qualité d’ajustement</a><ul>
<li class="chapter" data-level="9.7.1" data-path="GLM.html"><a href="GLM.html#le-pseudo-r2"><i class="fa fa-check"></i><b>9.7.1</b> Le pseudo <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="9.7.2" data-path="GLM.html"><a href="GLM.html#le-chi2-de-pearson-généralisé"><i class="fa fa-check"></i><b>9.7.2</b> Le <span class="math inline">\(\chi^2\)</span> de Pearson généralisé</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="GLM.html"><a href="GLM.html#ResidusGLM"><i class="fa fa-check"></i><b>9.8</b> Diagnostic, résidus</a></li>
<li class="chapter" data-level="9.9" data-path="GLM.html"><a href="GLM.html#en-résumé-7"><i class="fa fa-check"></i><b>9.9</b> En résumé</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="RegLogistique.html"><a href="RegLogistique.html"><i class="fa fa-check"></i><b>10</b> Régression logistique</a><ul>
<li class="chapter" data-level="10.1" data-path="RegLogistique.html"><a href="RegLogistique.html#introduction-2"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="RegLogistique.html"><a href="RegLogistique.html#pourquoi-des-modèles-particuliers"><i class="fa fa-check"></i><b>10.2</b> Pourquoi des modèles particuliers ?</a></li>
<li class="chapter" data-level="10.3" data-path="RegLogistique.html"><a href="RegLogistique.html#odds-et-odds-ratio"><i class="fa fa-check"></i><b>10.3</b> Odds et odds ratio</a></li>
<li class="chapter" data-level="10.4" data-path="RegLogistique.html"><a href="RegLogistique.html#régression-logistique-simple"><i class="fa fa-check"></i><b>10.4</b> Régression logistique simple</a><ul>
<li class="chapter" data-level="10.4.1" data-path="RegLogistique.html"><a href="RegLogistique.html#subquanti"><i class="fa fa-check"></i><b>10.4.1</b> Avec une variable explicative quantitative</a></li>
<li class="chapter" data-level="10.4.2" data-path="RegLogistique.html"><a href="RegLogistique.html#sect1expquali"><i class="fa fa-check"></i><b>10.4.2</b> Avec une variable explicative qualitative</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="RegLogistique.html"><a href="RegLogistique.html#régression-logistique-multiple"><i class="fa fa-check"></i><b>10.5</b> Régression logistique multiple</a><ul>
<li class="chapter" data-level="10.5.1" data-path="RegLogistique.html"><a href="RegLogistique.html#modèle-sans-interaction"><i class="fa fa-check"></i><b>10.5.1</b> Modèle sans interaction</a></li>
<li class="chapter" data-level="10.5.2" data-path="RegLogistique.html"><a href="RegLogistique.html#modèle-avec-interactions"><i class="fa fa-check"></i><b>10.5.2</b> Modèle avec interactions</a></li>
<li class="chapter" data-level="10.5.3" data-path="RegLogistique.html"><a href="RegLogistique.html#etude-complémentaire-du-modèle-retenu"><i class="fa fa-check"></i><b>10.5.3</b> Etude complémentaire du modèle retenu</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="RegLogistique.html"><a href="RegLogistique.html#quelques-codes-avec-python"><i class="fa fa-check"></i><b>10.6</b> Quelques codes avec python</a></li>
<li class="chapter" data-level="10.7" data-path="RegLogistique.html"><a href="RegLogistique.html#régression-polytomique"><i class="fa fa-check"></i><b>10.7</b> Régression polytomique</a><ul>
<li class="chapter" data-level="10.7.1" data-path="RegLogistique.html"><a href="RegLogistique.html#régression-multinomiale-ou-polytomique-non-ordonnée"><i class="fa fa-check"></i><b>10.7.1</b> Régression multinomiale ou polytomique non-ordonnée</a></li>
<li class="chapter" data-level="10.7.2" data-path="RegLogistique.html"><a href="RegLogistique.html#régression-polytomique-ordonnée"><i class="fa fa-check"></i><b>10.7.2</b> Régression polytomique ordonnée</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="RegLogLin.html"><a href="RegLogLin.html"><i class="fa fa-check"></i><b>11</b> Régression de Poisson / régression loglinéaire</a><ul>
<li class="chapter" data-level="11.1" data-path="RegLogLin.html"><a href="RegLogLin.html#modèle-de-régression-loglinéaire"><i class="fa fa-check"></i><b>11.1</b> Modèle de régression loglinéaire</a><ul>
<li class="chapter" data-level="11.1.1" data-path="RegLogLin.html"><a href="RegLogLin.html#pourquoi-un-modèle-particulier"><i class="fa fa-check"></i><b>11.1.1</b> Pourquoi un modèle particulier ?</a></li>
<li class="chapter" data-level="11.1.2" data-path="RegLogLin.html"><a href="RegLogLin.html#estimation-des-paramètres-3"><i class="fa fa-check"></i><b>11.1.2</b> Estimation des paramètres</a></li>
<li class="chapter" data-level="11.1.3" data-path="RegLogLin.html"><a href="RegLogLin.html#ajustement-et-prédiction"><i class="fa fa-check"></i><b>11.1.3</b> Ajustement et prédiction</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="RegLogLin.html"><a href="RegLogLin.html#exemple-de-régression-loglinéaire-avec-r"><i class="fa fa-check"></i><b>11.2</b> Exemple de régression loglinéaire avec R</a><ul>
<li class="chapter" data-level="11.2.1" data-path="RegLogLin.html"><a href="RegLogLin.html#régression-loglinéaire-simple"><i class="fa fa-check"></i><b>11.2.1</b> Régression loglinéaire simple</a></li>
<li class="chapter" data-level="11.2.2" data-path="RegLogLin.html"><a href="RegLogLin.html#régression-loglinéaire-multiple"><i class="fa fa-check"></i><b>11.2.2</b> Régression loglinéaire multiple</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="RegLogLin.html"><a href="RegLogLin.html#sur-dispersion-et-modèle-binomial-négatif"><i class="fa fa-check"></i><b>11.3</b> Sur-dispersion et modèle binomial négatif</a></li>
<li class="chapter" data-level="11.4" data-path="RegLogLin.html"><a href="RegLogLin.html#quelques-codes-avec-python-1"><i class="fa fa-check"></i><b>11.4</b> Quelques codes avec python</a></li>
</ul></li>
<li class="appendix"><span><b>Annexes</b></span></li>
<li class="chapter" data-level="A" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html"><i class="fa fa-check"></i><b>A</b> Rappels de probabilités, statistiques et d’optimisation</a><ul>
<li class="chapter" data-level="A.1" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#rappels-sur-les-échantillons-gaussiens"><i class="fa fa-check"></i><b>A.1</b> Rappels sur les échantillons gaussiens</a><ul>
<li class="chapter" data-level="A.1.1" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#la-loi-normale"><i class="fa fa-check"></i><b>A.1.1</b> La loi normale</a></li>
<li class="chapter" data-level="A.1.2" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#vecteurs-gaussiens"><i class="fa fa-check"></i><b>A.1.2</b> Vecteurs gaussiens</a></li>
<li class="chapter" data-level="A.1.3" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#loi-du-khi-deux-loi-de-student-loi-de-fisher"><i class="fa fa-check"></i><b>A.1.3</b> Loi du khi-deux, loi de Student, loi de Fisher</a></li>
<li class="chapter" data-level="A.1.4" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#estimation-de-la-moyenne-et-de-la-variance-dun-échantillon-gaussien"><i class="fa fa-check"></i><b>A.1.4</b> Estimation de la moyenne et de la variance d’un échantillon gaussien</a></li>
<li class="chapter" data-level="A.1.5" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#construction-dintervalles-de-confiance"><i class="fa fa-check"></i><b>A.1.5</b> Construction d’intervalles de confiance</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#estimation-sans-biais-de-variance-minimale"><i class="fa fa-check"></i><b>A.2</b> Estimation sans biais de variance minimale</a></li>
<li class="chapter" data-level="A.3" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#Newton-Raphson"><i class="fa fa-check"></i><b>A.3</b> La méthode de Newton-Raphson</a></li>
<li class="chapter" data-level="A.4" data-path="rappels-de-probabilités-statistiques-et-doptimisation.html"><a href="rappels-de-probabilités-statistiques-et-doptimisation.html#théorème-central-limite-condition-de-lindeberg"><i class="fa fa-check"></i><b>A.4</b> Théorème central limite: condition de Lindeberg</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html"><i class="fa fa-check"></i><b>B</b> Preuves de quelques résultats du cours</a><ul>
<li class="chapter" data-level="B.1" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html#ProofFisher"><i class="fa fa-check"></i><b>B.1</b> Preuve pour le test de Fisher</a></li>
<li class="chapter" data-level="B.2" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html#annexe:ortho"><i class="fa fa-check"></i><b>B.2</b> Preuve de la proposition @ref(prp:Proportho)</a></li>
<li class="chapter" data-level="B.3" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html#annexe:risque"><i class="fa fa-check"></i><b>B.3</b> Preuve de la proposition @ref(prp:risque)</a></li>
<li class="chapter" data-level="B.4" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html#annexe:KL"><i class="fa fa-check"></i><b>B.4</b> Preuve de la proposition @ref(prp:KL)</a></li>
<li class="chapter" data-level="B.5" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html#annexe:Mallows"><i class="fa fa-check"></i><b>B.5</b> Critère du <span class="math inline">\(C_p\)</span> de Mallows</a></li>
<li class="chapter" data-level="B.6" data-path="preuves-de-quelques-résultats-du-cours.html"><a href="preuves-de-quelques-résultats-du-cours.html#annexe:Sj"><i class="fa fa-check"></i><b>B.6</b> Preuve de la proposition @ref(prp:eqSj)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li>Cathy Maugis-Rabusseau</li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modèle linéaire général et modèle linéaire généralisé</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="preuves-de-quelques-résultats-du-cours" class="section level1">
<h1><span class="header-section-number">B</span> Preuves de quelques résultats du cours</h1>
<div id="ProofFisher" class="section level2">
<h2><span class="header-section-number">B.1</span> Preuve pour le test de Fisher</h2>
<p>On reprend les notations du chapitre <a href="Test.html#Test">4</a>. Rappelons la nature de chaque objet :
<span class="math inline">\(\theta\in\mathbb{R}^k\)</span>, <span class="math inline">\(C\in\mathcal{M}_{qk}(\mathbb{R})\)</span>, <span class="math inline">\(X_0\in\mathcal{M}_{nk_0}(\mathbb{R})\)</span> et <span class="math inline">\(X\in\mathcal{M}_{nk}(\mathbb{R})\)</span> avec <span class="math inline">\(Im(X_0)\subset Im(X)\)</span>.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-92" class="proposition"><strong>Proposition B.1  </strong></span>On veut tester
<span class="math display">\[
\mathcal{H}_0 : Y = X_0\beta + \varepsilon \hspace{0.3cm}(M_0) \textrm{ contre } \mathcal{H}_1 : Y=X\theta +\varepsilon \hspace{0.3cm}(M_1)
\]</span>
i.e
<span class="math display">\[
\mathcal{H}_0 : C\theta = 0 \textrm{ contre } \mathcal{H}_1 : C\theta \neq 0.
\]</span></p>
<ul>
<li><p><strong>Test 1</strong> :
La statistique de test
<span class="math display">\[
F = \frac{SCR_0 - SCR / (k-k_0)}{SCR/(n-k)} = \frac{\|X \widehat{\theta} - X_0 \widehat{\beta}\|^2 / (k-k_0)}{\|Y - X \widehat{\theta}\|^2 / (n-k)}\underset{\mathcal{H}_0}{\sim} \mathcal{F}(k-k_0,n-k)
\]</span>
et la zone de rejet est donnée par
<span class="math display">\[
\mathcal{R} =\{F \geq f_{1-\alpha,k-k_0,n-k}\}.
\]</span></p></li>
<li><p><strong>Test 2</strong> :
La statistique de test
<span class="math display">\[
\tilde{F} = \frac{[C\widehat{\theta}]&#39; [C (X&#39;X)^{-1} C&#39;]^{-1} [C\widehat{\theta}] /q}{SCR/(n-k)}  \underset{\mathcal{H}_0}{\sim} \mathcal{F}(q,n-k)
\]</span>
et la zone de rejet est donnée par
<span class="math display">\[
\mathcal{R} =\{\tilde F \geq f_{1-\alpha,q,n-k}\}.
\]</span>
Ces deux tests sont identiques.</p></li>
</ul>
</div>
<div class="proof">
<p><span id="unlabeled-div-93" class="proof"><em>Proof</em>. </span>Nous allons prouver le résultat du test de Fisher, en particulier que ces deux tests sont équivalents.</p>
<ul>
<li><strong>Montrons que <span class="math inline">\(\tilde{F} \underset{\mathcal{H}_0}{\sim} \mathcal{F}(q,n-k)\)</span></strong></li>
</ul>
<p>L’application <span class="math inline">\(C : \mathbb{R}^k \to \mathbb{R}^q\)</span> est surjective car <span class="math inline">\(rg(C)=q\)</span> par hypothèse.</p>
<p>On a <span class="math inline">\(C\widehat{\theta} \sim \mathcal{N}_q(C\theta,\sigma^2 \Delta)\)</span> avec <span class="math inline">\(\Delta = C(X&#39;X)^{-1}C&#39;\)</span>.
La matrice <span class="math inline">\((X&#39;X)^{-1}\)</span> étant inversible, elle peut s’écrire sous la forme <span class="math inline">\(AA&#39;\)</span> où <span class="math inline">\(A\in\mathcal{M}_k(\mathbb{R})\)</span> inversible. De plus, <span class="math inline">\(rg(\Delta)=rg(CAA&#39;C&#39;)=rg(A&#39;C&#39;) = q - dim(Ker(A&#39;C&#39;))\)</span>.
Or <span class="math inline">\(A&#39;C&#39;x=0_k \Leftrightarrow C&#39;x=0_k \Rightarrow x=0_q\)</span> car <span class="math inline">\(A\)</span> inversible et <span class="math inline">\(C&#39;\)</span> injective. Ainsi <span class="math inline">\(rg(\Delta)=q\)</span> et <span class="math inline">\(\Delta = (CA)(CA)&#39;\in\mathcal{M}_q(\mathbb{R})\)</span>. <span class="math inline">\(\Delta\)</span> étant inversible, elle se décompose en <span class="math inline">\(\Delta=BB&#39;\)</span> avec <span class="math inline">\(B\in\mathcal{M}_q(\mathbb{R})\)</span> inversible.</p>
<p>Sous <span class="math inline">\(\mathcal{H}_0\)</span>, <span class="math inline">\(C\widehat{\theta}\sim \mathcal{N}_q(0_q,\sigma^2 \Delta)\)</span> donc <span class="math inline">\(B^{-1} C\widehat{\theta} \sim\mathcal{N}_q(0_q,\sigma^2 I_q)\)</span>.
On en déduit donc que
<span class="math inline">\([B^{-1} C\widehat{\theta}]&#39; [B^{-1} C\widehat{\theta}] / \sigma^2 \sim \chi^2(q).\)</span> De plus <span class="math inline">\(SCR= (n-k) \widehat{\sigma^2}\sim \sigma^2 \chi^2(n-k)\)</span> et <span class="math inline">\(\widehat{\theta}\)</span> et <span class="math inline">\(\widehat{\sigma^2}\)</span> sont indépendants. On en conclut que
<span class="math display">\[
\frac{[B^{-1} C\widehat{\theta}]&#39; [B^{-1} C\widehat{\theta} ] /q}{SCR/(n-k)} = \frac{[C\widehat{\theta}]&#39; [C(X&#39;X)^{-1}C&#39;]^{-1} [C\widehat{\theta} ] /q}{SCR/(n-k)} \underset{\mathcal{H}_0}{\sim} \mathcal{F}(q,n-k).
\]</span></p>
<ul>
<li><strong>Montrons que <span class="math inline">\(F=\tilde F\)</span></strong></li>
</ul>
<p>Tout d’abord,
<span class="math display">\[\begin{eqnarray*}
\|Y - X_0 \widehat{\beta}\|^2 &amp;=&amp; \underset{\beta\in\mathbb{R}^q}{\min} \|Y - X_0 \beta\|^2\\
&amp;=&amp; \underset{u\in Im(X_0)}{\min} \|Y - u\|^2\\
&amp;=&amp; \underset{u\in X (Ker(C)) }{\min} \|Y - u\|^2\\
&amp;=&amp; \underset{\theta\in Ker(C) }{\min} \|Y - X\theta\|^2\\
&amp;=&amp;\|Y - X \tilde \theta\|^2.
\end{eqnarray*}\]</span></p>
<p>Le vecteur <span class="math inline">\(\tilde \theta\)</span> minimise <span class="math inline">\(\|Y - X\theta\|^2\)</span> sous la contrainte <span class="math inline">\(\theta\in Ker(C)\)</span>. Soit <span class="math inline">\(\lambda \in\mathbb{R}^q\)</span>. Pour déterminer <span class="math inline">\(\tilde \theta\)</span> on résout,
<span class="math display">\[\begin{eqnarray*}
&amp;&amp; \frac{\partial }{\partial \theta} [(Y-X\theta)&#39; (Y-X\theta) + \lambda&#39; C\theta ] = 0_k\\
\Leftrightarrow&amp;&amp; \frac{\partial }{\partial \theta} [Y&#39;Y - \theta&#39;X&#39;Y - Y&#39;X\theta + \theta&#39; X&#39; X \theta + \lambda&#39; C\theta ] = 0_k\\
\Leftrightarrow&amp; &amp;-2X&#39;Y + 2 X&#39; X \theta + C&#39;\lambda =0_k
\end{eqnarray*}\]</span>
donc <span class="math inline">\(\tilde \theta = (X&#39;X)^{-1}X&#39;Y - \frac 1 2 (X&#39;X)^{-1} C&#39;\lambda\)</span>.
En utilisant la contrainte <span class="math inline">\(C \tilde \theta=0_q\)</span>, on obtient que <span class="math inline">\(\frac 1 2 \lambda = \Delta^{-1} C(X&#39;X)^{-1} X&#39;Y\)</span> car <span class="math inline">\(\Delta\)</span> est inversible. Finalement,
<span class="math inline">\(\tilde \theta = (X&#39;X)^{-1}X&#39;Y - (X&#39;X)^{-1} C&#39; \Delta^{-1} C (X&#39;X)^{-1} X&#39;Y = \widehat{\theta} - (X&#39;X)^{-1} C&#39; \Delta^{-1} C\widehat{\theta}\)</span>.</p>
<p>Ainsi
<span class="math display">\[\begin{eqnarray*}
\|X \widehat{\theta} - X_0 \widehat{\beta}\|^2 &amp;=&amp; \|X \widehat{\theta} - X \tilde \theta\|^2\\
&amp;=&amp; \|X(X&#39;X)^{-1} C&#39; \Delta^{-1}C \widehat{\theta}\|^2\\
&amp;=&amp; (C \widehat{\theta})&#39; \Delta^{-1} C(X&#39;X)^{-1} X&#39;X (X&#39;X)^{-1} C&#39; \Delta^{-1} (C \widehat{\theta})\\
&amp;=&amp; (C \widehat{\theta})&#39; \Delta^{-1}(C \widehat{\theta}).
\end{eqnarray*}\]</span></p>
<ul>
<li><strong>Montrons que <span class="math inline">\(q=k-k_0\)</span></strong>
Soit <span class="math inline">\((e_1,\ldots,e_{k-q})\)</span> une base de <span class="math inline">\(Ker(C)\)</span> donc <span class="math inline">\((Xe_1,\ldots,Xe_{k-q})\)</span> est une famille génératrice de <span class="math inline">\(X(Ker(C))\)</span>.
On montre ensuite facilement que c’est une famille libre car <span class="math inline">\(X\)</span> est injective. Ainsi <span class="math inline">\(dim(X(Ker(C))) = dim(Im(X_0))=k-q=k_0\)</span>.</li>
</ul>
</div>
</div>
<div id="annexe:ortho" class="section level2">
<h2><span class="header-section-number">B.2</span> Preuve de la proposition <a href="ANOVA.html#prp:Proportho">7.5</a></h2>
<div class="proof">
<p><span id="unlabeled-div-94" class="proof"><em>Proof</em>. </span>On considère un modèle d’ANOVA à deux facteurs de la forme générale
<span class="math display">\[
Y = X \theta + \varepsilon = (\mathbb{1}_n, X_{(\alpha)}, X_{(\beta)}, X_{(\gamma)}) \theta + \varepsilon
\]</span>
avec <span class="math inline">\(\theta=(\mu,\alpha,\beta,\gamma)&#39;\)</span>, <span class="math inline">\(\alpha=(\alpha_1,\ldots,\alpha_I)\)</span>, <span class="math inline">\(\beta=(\beta_1,\ldots,\beta_J)\)</span> et <span class="math inline">\(\gamma=(\gamma_{11}, \ldots, \gamma_{IJ})\)</span>.</p>
<p>On considère les sous-espaces vectoriels suivants de <span class="math inline">\(\mathbb{R}^n\)</span> :
<span class="math display">\[
\begin{array}{l}
E_\mu = Vect(\mathbb{1}_n) \\
E_\alpha=\{X_{(\alpha)} \alpha; \sum_{i=1}^I n_{i+}\alpha_i =0\}  \\
E_\beta=\{X_{(\beta)} \beta; \sum_{j=1}^J n_{+j}\beta_j =0\}  \\
E_\gamma=\{X_{(\gamma)} \gamma; \sum_{i=1}^I n_{ij}\gamma_{ij} =\sum_{j=1}^J n_{ij}\gamma_{ij}=0\} 
\end{array}
\]</span>
On introduit les ensembles <span class="math inline">\(A_{(\alpha)}=\{\alpha;\ \sum_{i=1}^I n_{i+} \alpha_i =0\}\)</span> et <span class="math inline">\(A_{(\beta)}=\{\beta;\ \sum_{j=1}^J n_{+j} \beta_j =0\}\)</span></p>
<p>Commençons par caractériser que <span class="math inline">\(E_\mu\)</span>, <span class="math inline">\(E_\alpha\)</span>, <span class="math inline">\(E_\beta\)</span> et <span class="math inline">\(E_\gamma\)</span> sont orthogonaux : \
soit <span class="math inline">\(v^{(\mu)}\in E_\mu\)</span>, <span class="math inline">\(v^{(\alpha)}\in E_\alpha\)</span>, <span class="math inline">\(v^{(\beta)}\in E_\beta\)</span> et <span class="math inline">\(v^{(\gamma)}\in E_\gamma\)</span>. On a donc
<span class="math display">\[
\begin{array}{l}
&lt;v^{(\mu)},v^{(\alpha)} &gt; =\sum_{i,j,\ell} \mu \alpha_i =  \mu \sum_{i=1}^I n_{i+} \alpha_i = 0 \\
&lt;v^{(\mu)},v^{(\beta)} &gt; =\sum_{i,j,\ell} \mu \beta_j =  \mu \sum_{j=1}^J n_{+j} \beta_j = 0 \\
&lt;v^{(\mu)},v^{(\gamma)} &gt; =\sum_{i,j,\ell} \mu \gamma_{ij} =  \mu \sum_{i=1}^I \sum_{j=1}^J n_{ij} \gamma_{ij} = 0 \\
&lt;v^{(\alpha)},v^{(\gamma)} &gt; =\sum_{i,j,\ell} \alpha_i \gamma_{ij} = \sum_{i=1}^I  \alpha_i (\sum_{j=1}^J n_{ij} \gamma_{ij}) = 0 \\
&lt;v^{(\beta)},v^{(\gamma)} &gt; =\sum_{i,j,\ell} \beta_j \gamma_{ij} =  \sum_{j=1}^J \beta_j (\sum_{i=1}^In_{ij} \gamma_{ij}) = 0 \\
&lt;v^{(\alpha)},v^{(\beta)} &gt; =\sum_{i,j,\ell} \alpha_i \beta_{j} =  \sum_{i=1}^I \sum_{j=1}^J n_{ij} \alpha_i \beta_{j}  
\end{array}
\]</span>
On remarque que si <span class="math inline">\(n_{ij}= n_{i+} n_{+j} / n\)</span>, alors
<span class="math display">\[
    &lt;v^{(\alpha)},v^{(\beta)} &gt; =  \sum_{i=1}^I  \frac{n_{i+}}{n} \alpha_i \left(\sum_{j=1}^J n_{+j} \beta_{j} \right)  =0.
\]</span>
Réciproquement, supposons que <span class="math inline">\(E_\alpha\)</span> et <span class="math inline">\(E_\beta\)</span> sont orthogonaux :
<span class="math display" id="eq:aux1">\[\begin{equation}
\tag{B.1}
\sum_{i=1}^I \sum_{j=1}^J n_{ij} \alpha_i \beta_{j}  = 0,\  \forall \alpha\in A_{(\alpha)},\ \forall \beta\in A_{(\beta)}.
\end{equation}\]</span></p>
<p>Fixons <span class="math inline">\(\alpha\)</span>.  est vrai pour tout <span class="math inline">\(\beta\in A_{(\beta)}\)</span> et <span class="math inline">\(\sum_{j=1}^J n_{+j} \beta_j=0\)</span> donc
<span class="math display">\[
\sum_{j=1}^J \left(\sum_{i=1}^I  n_{ij} \alpha_i \right) \beta_{j} = 0 = \sum_{j=1}^J n_{+j} \beta_j.
\]</span>
Ainsi, <span class="math inline">\(\sum_{i=1}^I n_{ij} \alpha_i = c_j n_{+j}\)</span> où <span class="math inline">\(c_j\)</span> constante pour <span class="math inline">\(j=1,\ldots,J\)</span>.
En sommant sur <span class="math inline">\(j\)</span>,<br />
<span class="math display">\[
\sum_{j=1}^J \left(\sum_{i=1}^I  n_{ij} \alpha_i \right) = \sum_{j=1}^J  c_j n_{+j} = \sum_{i=1}^I  n_{i+} \alpha_i =0
\]</span>
d’où <span class="math inline">\(c_j=0\)</span> pour tout <span class="math inline">\(j\)</span> donc <span class="math inline">\(\sum_{i=1}^I n_{ij} \alpha_i =0\)</span>.</p>
<p>A nouveau, pour tout <span class="math inline">\(\alpha\in A_{(\alpha)}\)</span> et pour tout <span class="math inline">\(j\)</span>,
<span class="math display">\[
\sum_{i=1}^I  n_{ij} \alpha_i = 0 = \sum_{i=1}^I  n_{i+} \alpha_i
\]</span>
donc <span class="math inline">\(n_{ij}\)</span> et <span class="math inline">\(n_{i+}\)</span> sont proportionnels pour tout <span class="math inline">\(i\)</span> :
<span class="math display">\[n_{ij} = d_j n_{i+} \textrm{ avec } d_j \textrm{ constante}.\]</span>
Ainsi
$<em>{i=1}^I n</em>{ij} = <em>{i=1}^I d_j n</em>{i+} = c_j n = n_{+j} $ d’où <span class="math inline">\(d_j = n_{+j}/n\)</span> et <span class="math inline">\(n_{ij} = (n_{+j}/n ) n_{i+}\)</span>.</p>
</div>
</div>
<div id="annexe:risque" class="section level2">
<h2><span class="header-section-number">B.3</span> Preuve de la proposition <a href="regression.html#prp:risque">6.2</a></h2>
<div class="proof">
<p><span id="unlabeled-div-95" class="proof"><em>Proof</em>. </span><span class="math display">\[\begin{eqnarray*}
\mathcal{R}(m,m^\star) &amp;=&amp; \mathbb{E}\left[\|X_{(m)} \hat\theta_{(m)} - \mu^\star\|^2\right] \\
&amp;=&amp; \mathbb{E}\left[\|X_{(m)} \hat\theta_{(m)} - \mu^\star_{(m)} +  \mu^\star_{(m)}  - \mu^\star\|^2\right] \hspace*{0.5cm} \textrm{ avec } \mu^\star_{(m)}=P_{[X_{(m)}]}\mu^\star\\
&amp;=&amp;\mathbb{E}\left[\|X_{(m)} \hat\theta_{(m)} - \mu^\star_{(m)}\|^2\right]  +  \mathbb{E}\left[\|\mu^\star_{(m)}  - \mu^\star\|^2\right] \hspace*{0.5cm} \textrm{ par Pythagore }\\
&amp;=&amp;\mathbb{E}\left[\|X_{(m)} \hat\theta_{(m)} - \mu^\star_{(m)}\|^2\right] +  \|\mu^\star_{(m)}  - \mu^\star\|^2.
\end{eqnarray*}\]</span>
Or
<span class="math display">\[
X_{(m)} \hat\theta_{(m)}  = P_{[X_{(m)}]} Y = P_{[X_{(m)}]} \left(X_{(m^\star)} \theta_{(m^\star)} + \varepsilon_{(m^\star)}\right) = \mu^\star_{(m)} + P_{[X_{(m)}]} \varepsilon_{(m^\star)},
\]</span>
donc
<span class="math display">\[
\|X_{(m)} \hat\theta_{(m)} - \mu^\star_{(m)}\|^2 = \|P_{[X_{(m)}]} \varepsilon_{(m^\star)}\|^2 \sim (\sigma{^\star})^2 \chi^2(|m|+1)
\]</span>
d’après le théorème de Cochran. Ainsi <span class="math inline">\(\mathbb{E}\left[\|X_{(m)} \hat\theta_{(m)} - \mu^\star_{(m)}\|^2\right] = (\sigma{^\star})^2 (|m|+1)\)</span>.</p>
</div>
</div>
<div id="annexe:KL" class="section level2">
<h2><span class="header-section-number">B.4</span> Preuve de la proposition <a href="regression.html#prp:KL">6.3</a></h2>
<div class="proof">
<p><span id="unlabeled-div-96" class="proof"><em>Proof</em>. </span>Sous le modèle <span class="math inline">\(m^\star\)</span>, la densité de <span class="math inline">\(Y=(Y_1,\ldots,Y_n)&#39;\)</span> vaut
<span class="math display">\[
f^\star(Y) = (2\pi\sigma^{\star\,2})^{-n/2} \exp\left(-\frac{1}{2\sigma^{\star\,2}} \|Y - \mu^\star\|^2\right).
\]</span>
Sous le modèle <span class="math inline">\(m\)</span>, la densité de <span class="math inline">\(Y\)</span> vaut
<span class="math display">\[
f_{(m)}(Y) = (2\pi\sigma_{(m)}^{2})^{-n/2} \exp\left(-\frac{1}{2\sigma_{(m)}^{2}} \|Y - \mu_{(m)}\|^2\right).
\]</span>
Ainsi
<span class="math display">\[
\ln\left(\frac{f^\star(Y)}{f_{(m)}(Y)}\right) = \frac n 2 \ln\left(\frac{\sigma_{(m)}^2}{\sigma^{\star\,2}}\right) + \frac{\|Y - \mu_{(m)}\|^2}{2 \sigma_{(m)}^2} -  \frac{\|Y - \mu^\star\|^2}{2 \sigma^{\star\,2}}. 
\]</span>
D’où
<span class="math display">\[\begin{eqnarray*}
KL(m^\star,m) &amp;=&amp; \mathbb{E}_{f^\star}\left[\ln\left(\frac{f^\star(Y)}{f_{(m)}(Y)}\right)\right]\\
&amp;=&amp;  \frac n 2 \ln\left(\frac{\sigma_{(m)}^2}{\sigma^{\star\,2}}\right) 
 + \frac{1}{2 \sigma_{(m)}^2} \mathbb{E}_{f^\star}\left[\|Y - \mu_{(m)}\|^2\right]   -  \frac{1}{2 \sigma^{\star\,2}}  \mathbb{E}_{f^\star}\left[ \|Y - \mu^\star\|^2\right]. 
\end{eqnarray*}\]</span>
Or <span class="math inline">\(\mathbb{E}_{f^\star}\left[ \|Y - \mu^\star\|^2\right] = \mathbb{E}_{f^\star}\left[ \|\varepsilon^\star\|^2\right] = n \sigma^{\star\,2}\)</span> et
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}_{f^\star}\left[\|Y - \mu_{(m)}\|^2\right]  
&amp;=&amp; \mathbb{E}_{f^\star}\left[\|Y - \mu^\star + \mu^\star - \mu_{(m)}\|^2\right] \\
&amp;=&amp; \mathbb{E}_{f^\star}\left[\|Y - \mu^\star \|^2 \right]  + \|\mu^\star - \mu_{(m)}\|^2 + 2 \mathbb{E}_{f^\star}\left[(\mu^\star - \mu_{(m)})&#39; (Y - \mu^\star)\right]\\
&amp;=&amp; n\sigma^{\star\,2} + \|\mu^\star - \mu_{(m)}\|^2
\end{eqnarray*}\]</span>
car <span class="math inline">\(\mathbb{E}_{f^\star}\left[Y\right] = \mu^\star\)</span>. Finalement, on obtient que
<span class="math display">\[\begin{eqnarray*}
KL(m^\star,m) 
&amp;=&amp; \frac n 2 \ln\left(\frac{\sigma_{(m)}^2}{\sigma^{\star\,2}}\right) + \frac{n\sigma^{\star\,2} + \|\mu^\star - \mu_{(m)}\|^2
}{2 \sigma_{(m)}^2} -  \frac{n\sigma^{\star\,2} }{2 \sigma^{\star\,2}} \\
&amp;=&amp; \frac n 2 \left[ \ln\left(\frac{\sigma_{(m)}^2}{\sigma^{\star\,2}}\right)  +  \frac{\sigma^{\star\,2} }{ \sigma_{(m)}^2} -1 \right] + \frac{ \|\mu^\star - \mu_{(m)}\|^2
}{2 \sigma_{(m)}^2}.
\end{eqnarray*}\]</span></p>
</div>
</div>
<div id="annexe:Mallows" class="section level2">
<h2><span class="header-section-number">B.5</span> Critère du <span class="math inline">\(C_p\)</span> de Mallows</h2>
<p>Soit <span class="math inline">\(m\in \mathcal{M}\)</span> fixé. On rappelle que d’après la proposition <a href="regression.html#prp:risque">6.2</a>, le risque quadratique entre <span class="math inline">\(m\)</span> et <span class="math inline">\(m^\star\)</span> vaut :
<span class="math display">\[\mathcal{R}(m,m^\star)=  \|\mu^\star_{(m)}  - \mu^\star\|^2 + (\sigma{^\star})^2 (|m|+1).\]</span>
Commençons par essayer d’estimer le terme de biais. D’après le théorème de Pythagore et le théorème de Cochran, on a :
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}\left[ \| Y - \widehat{Y}_{(m)} \|^2\right] &amp; = &amp; \mathbb{E}\left[\| Y - \mu_{(m)}^{\star} \|^2\right] - \mathbb{E}\left[ \| \widehat{Y}_{(m)} - \mu_{(m)}^{\star}\|^2\right], \\
  &amp; = &amp; \mathbb{E}\left[\|Y-\mu^{\star}+\mu^{\star}-\mu_{(m)}^\star\|^2\right]- \mathbb{E}\left[ \| \widehat{Y}_{(m)} - \mu_{(m)}^{\star} \|^2\right], \\
  &amp; = &amp; \mathbb{E}\left[\| Y - \mu^{\star} \|^2\right] +\| \mu^{\star} - \mu_{(m)}^{\star} \|^2 - (|m|+1) \sigma^{\star\,2},\\
  &amp; = &amp; \| \mu^\star - \mu_{(m)}^\star \|^2 + n\sigma^{\star\,2} - (|m|+1) \sigma^{\star\,2},
\end{eqnarray*}\]</span>
ou encore
<span class="math display" id="eq:estbiais">\[\begin{equation}
\| \mu^\star- \mu_{(m)}^\star \|^2 = \mathbb{E}\left[\left\| Y - \widehat{Y}_{(m)} \right\|^2\right] + (|m|+1) \sigma^{\star\,2} - n\sigma^{\star\,2}.
\tag{B.2}
\end{equation}\]</span></p>
<p>D’après <a href="preuves-de-quelques-résultats-du-cours.html#eq:estbiais">(B.2)</a>, le terme de biais <span class="math inline">\(\| \mu^\star - \mu_{(m)}^\star \|^2\)</span> peut donc ^etre estimé par <span class="math inline">\(\| Y - \widehat{Y}_{(m)} \|^2 + (|m|+1) \sigma^{\star\,2}\)</span> (on néglige le terme en <span class="math inline">\(n\sigma^{\star\,2}\)</span> puisque ce dernier ne dépend pas de <span class="math inline">\(m\)</span> et n’interviendra donc pas dans la minimisation).</p>
<p>Si la variance est connue, on obtient alors le critère :
<span class="math display">\[ C_p(m)= \| Y - \widehat{Y}_{(m)} \|^2 + 2|m| \sigma^{\star\,2}.\]</span>
On retiendra alors le modèle <span class="math inline">\(\hat m_{CP}\)</span> vérifiant :
<span class="math display">\[ \hat m_{CP} = \mathrm{arg} \min_{m\in \mathcal{M}} C_p(m).\]</span>
Dans le cas où la variance est inconnue, on utilisera l’estimateur <span class="math inline">\(\widehat{\sigma^2} = \widehat{\sigma^2}_{(m_p)}\)</span> où <span class="math inline">\(m_p=\lbrace 1,\dots, p \rbrace\)</span> est le modèle prenant en compte tous les régresseurs.</p>
</div>
<div id="annexe:Sj" class="section level2">
<h2><span class="header-section-number">B.6</span> Preuve de la proposition <a href="#prp:eqSj"><strong>??</strong></a></h2>
<p>Dans le cas d’une famille exponentielle,
<span class="math display">\[
l(\underline{Y};\theta) = \underset{i=1}{\stackrel{n}{\sum}} \left\{ \frac{Y_i \omega_i - b(\omega_i)}{\gamma(\phi)} + c(Y_i,\phi) \right\} = \underset{i=1}{\stackrel{n}{\sum}}  \ell_i
\]</span>
avec <span class="math inline">\(\mu_i=b&#39;(\omega_i)\)</span>, <span class="math inline">\(\eta_i=g(\mu_i)=\textbf{x}_i \theta\)</span>, <span class="math inline">\(Var(Y_i)=b&#39;&#39;(\omega_i) \gamma(\phi)\)</span>.</p>
<p>Calculons
<span class="math display">\[
\frac{\partial\ell_i}{\partial\theta_j}=\frac{\partial\ell_i}{\partial\omega_i}\frac{\partial\omega_i}{\partial\mu_i}\frac{\partial\mu_i}{\partial\eta_i}\frac{\partial\eta_i}{\partial\theta_j} :
\]</span>
Comme
<span class="math display">\[\begin{eqnarray*}
\frac{\partial\ell_i}{\partial\omega_i}&amp;=&amp;[Y_i-b&#39;(\omega_i)]/\gamma(\phi)=(Y_i-\mu_i)/\gamma(\phi),\\
\frac{\partial\omega_i}{\partial\mu_i}&amp;=&amp;1/b&#39;&#39;(\omega_i)=\gamma(\phi) / \text{Var}(Y_i),\\
\frac{\partial\eta_i}{\partial\theta_j}&amp;=&amp;x_{i}^{(j)} \quad \text{car}\quad \eta_i=\mathbf{x}_i\bs{\theta},\\
\frac{\partial\mu_i}{\partial\eta_i}&amp;\quad&amp; \text{dépend de la fonction lien}\quad\eta_i=g(\mu_i),
\end{eqnarray*}\]</span>
on obtient que
<span class="math display">\[
S_j = \frac{\partial l(\underline{Y}; \theta)}{\partial \theta_j} = \sum_{i=1}^n\frac{(Y_i-\mu_i)x_{i}^{(j)}}{\text{Var}(Y_i)}\ \frac{\partial\mu_i}{\partial\eta_i}\quad \forall j=0,\ldots,p.
\]</span></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="rappels-de-probabilités-statistiques-et-doptimisation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Bookdown-poly.pdf", "Bookdown-poly.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
